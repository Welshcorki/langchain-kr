import gradio as gr
from operator import itemgetter
from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableLambda, RunnablePassthrough, Runnable
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
import os
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class MyConversationChain(Runnable):
    def __init__(self, llm, prompt, memory, input_key="input"):
        self.prompt = prompt
        self.memory = memory
        self.input_key = input_key
        
        self.chain = (
            RunnablePassthrough.assign(
                chat_history=RunnableLambda(self.memory.load_memory_variables)
                | itemgetter(memory.memory_key)
            )
            | prompt
            | llm
            | StrOutputParser()
        )
    
    def invoke(self, query, configs=None, **kwargs):
        answer = self.chain.invoke({self.input_key: query})
        self.memory.save_context(inputs={"human": query}, outputs={"ai": answer})
        return answer
    
    def clear_memory(self): # ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
        self.memory.clear()


class GradioChatApp:    # gradio ì±—ì•±ì´ ë™ì‘ë˜ëŠ” ë°©ì‹
    def __init__(self, model_name="gpt-4o-mini", temperature=0.7):
        self.model_name = model_name
        self.temperature = temperature
        self.conversation_chain = None
        self.initialize_chain()
    
    def initialize_chain(self):
        # ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”
        llm = ChatOpenAI(model_name=self.model_name, temperature=self.temperature)
        
        # ëŒ€í™”í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", "You are a helpful and friendly AI assistant. Respond in Korean unless otherwise requested."),
                MessagesPlaceholder(variable_name="chat_history"),
                ("human", "{input}"),
            ]
        )
        
        # ëŒ€í™” ë²„í¼ ë©”ëª¨ë¦¬ ìƒì„±
        # memory = ConversationBufferMemory(return_messages=True, memory_key="chat_history")
        
        # ConversationSummaryMemory ì‚¬ìš©
        memory = ConversationSummaryMemory(
            llm=llm, # ìš”ì•½ì„ ìœ„í•´ LLM ëª¨ë¸ ì „ë‹¬
            return_messages=True,
            memory_key="chat_history",
        )

        # ëŒ€í™” ì²´ì¸ ìƒì„±
        self.conversation_chain = MyConversationChain(llm, prompt, memory)
    
    def respond(self, message, history):
        """Gradio ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ„í•œ ì‘ë‹µ í•¨ìˆ˜"""
        try:
            # LangChain ëŒ€í™” ì²´ì¸ì„ í†µí•´ ì‘ë‹µ ìƒì„±
            response = self.conversation_chain.invoke(message)
            return response
        except Exception as e:
            return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def clear_conversation(self):
        """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
        if self.conversation_chain:
            self.conversation_chain.clear_memory()
        return None, None
    
    def update_model_settings(self, model_name, temperature):
        """ëª¨ë¸ ì„¤ì • ì—…ë°ì´íŠ¸"""
        self.model_name = model_name
        self.temperature = temperature
        self.initialize_chain()
        return "ëª¨ë¸ ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."


def create_gradio_interface():
    """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    app = GradioChatApp()
    
    with gr.Blocks(title="LangChain Gradio Chat", theme=gr.themes.Soft()) as demo:
        gr.Markdown(
            """
            # ğŸ¤– LangChain Gradio Chat
            LangChainê³¼ OpenAIë¥¼ í™œìš©í•œ ëŒ€í™”í˜• AI ì±—ë´‡ì…ë‹ˆë‹¤.
            """
        )
        
        with gr.Row():
            with gr.Column(scale=3):
                chatbot = gr.Chatbot(
                    label="ëŒ€í™”",
                    height=500,
                    bubble_full_width=False,
                    avatar_images=(None, "ğŸ¤–")
                )
                msg = gr.Textbox(
                    label="ë©”ì‹œì§€ ì…ë ¥",
                    placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”... (Enter í‚¤ë¡œ ì „ì†¡)",
                    lines=2
                )
                with gr.Row():
                    submit = gr.Button("ì „ì†¡", variant="primary")
                    clear = gr.Button("ëŒ€í™” ì´ˆê¸°í™”")
            
            with gr.Column(scale=1):
                gr.Markdown("### âš™ï¸ ì„¤ì •")
                model_dropdown = gr.Dropdown(
                    choices=["gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo"],
                    value="gpt-4o-mini",
                    label="ëª¨ë¸ ì„ íƒ"
                )
                temperature_slider = gr.Slider(
                    minimum=0,
                    maximum=2,
                    value=0.7,
                    step=0.1,
                    label="Temperature (ì°½ì˜ì„± ìˆ˜ì¤€)"
                )
                update_btn = gr.Button("ì„¤ì • ì ìš©", variant="secondary")
                settings_output = gr.Textbox(label="ì„¤ì • ìƒíƒœ", interactive=False)
                
                gr.Markdown(
                    """
                    ### ğŸ“ ì‚¬ìš© ë°©ë²•
                    1. ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ê³  Enter ë˜ëŠ” ì „ì†¡ ë²„íŠ¼ì„ í´ë¦­
                    2. AIê°€ ëŒ€í™” ë§¥ë½ì„ ê¸°ì–µí•˜ë©° ì‘ë‹µ
                    3. ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë ¤ë©´ 'ëŒ€í™” ì´ˆê¸°í™”' í´ë¦­
                    4. ëª¨ë¸ì´ë‚˜ Temperature ë³€ê²½ ì‹œ 'ì„¤ì • ì ìš©' í´ë¦­
                    """
                )
        
        # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì—°ê²°
        def user_submit(user_message, history):
            if not user_message:
                return "", history
            history = history or []
            return "", history + [[user_message, None]]
        
        def bot_respond(history):
            if history and history[-1][1] is None:
                user_message = history[-1][0]
                bot_message = app.respond(user_message, history[:-1])
                history[-1][1] = bot_message
            return history
        
        # ë©”ì‹œì§€ ì „ì†¡ ì´ë²¤íŠ¸
        msg.submit(user_submit, [msg, chatbot], [msg, chatbot]).then(
            bot_respond, chatbot, chatbot
        )
        submit.click(user_submit, [msg, chatbot], [msg, chatbot]).then(
            bot_respond, chatbot, chatbot
        )
        
        # ëŒ€í™” ì´ˆê¸°í™”
        clear.click(
            lambda: (app.clear_conversation(), "", []),
            outputs=[chatbot, msg, chatbot]
        )
        
        # ì„¤ì • ì—…ë°ì´íŠ¸
        update_btn.click(
            app.update_model_settings,
            inputs=[model_dropdown, temperature_slider],
            outputs=[settings_output]
        )
        
        # ì˜ˆì œ ì…ë ¥
        gr.Examples(
            examples=[
                "ì•ˆë…•í•˜ì„¸ìš”! ìê¸°ì†Œê°œë¥¼ í•´ì£¼ì„¸ìš”.",
                "íŒŒì´ì¬ìœ¼ë¡œ í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ì„ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
                "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?",
                "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”?",
                "ê±´ê°•í•œ ìƒí™œ ìŠµê´€ì— ëŒ€í•´ ì¡°ì–¸í•´ì£¼ì„¸ìš”."
            ],
            inputs=msg
        )
    
    return demo


if __name__ == "__main__":
    # Gradio ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
    demo = create_gradio_interface()
    demo.launch(
        share=False,  # Trueë¡œ ì„¤ì •í•˜ë©´ ê³µê°œ URL ìƒì„±
        server_name="0.0.0.0",  # ëª¨ë“  ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥
        server_port=7860,  # í¬íŠ¸ ì„¤ì •
        show_error=True
    )