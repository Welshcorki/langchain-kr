{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone\n",
    "\n",
    "Pinecone은 고성능 벡터 데이터베이스로, AI 및 머신러닝 애플리케이션을 위한 효율적인 벡터 저장 및 검색 솔루션입니다. \n",
    "\n",
    "Pinecone, Chroma, Faiss와 같은 벡터 데이터베이스들을 비교해보겠습니다. \n",
    "\n",
    "**Pinecone의 장점**\n",
    "\n",
    "1. 확장성: 대규모 데이터셋에 대해 뛰어난 확장성을 제공합니다.\n",
    "   \n",
    "2. 관리 용이성: 완전 관리형 서비스로, 인프라 관리 부담이 적습니다.\n",
    "   \n",
    "3. 실시간 업데이트: 데이터의 실시간 삽입, 업데이트, 삭제가 가능합니다.\n",
    "   \n",
    "4. 고가용성: 클라우드 기반으로 높은 가용성과 내구성을 제공합니다.\n",
    "   \n",
    "5. API 친화적: RESTful/Python API를 통해 쉽게 통합할 수 있습니다.\n",
    "\n",
    "**Pinecone의 단점**\n",
    "\n",
    "1. 비용: Chroma나 Faiss에 비해 상대적으로 비용이 높을 수 있습니다.\n",
    "   \n",
    "2. 커스터마이징 제한: 완전 관리형 서비스이기 때문에 세부적인 커스터마이징에 제한이 있을 수 있습니다.\n",
    "   \n",
    "3. 데이터 위치: 클라우드에 데이터를 저장해야 하므로, 데이터 주권 문제가 있을 수 있습니다.\n",
    "\n",
    "Chroma나 Faiss와 비교했을 때:\n",
    "\n",
    "- Chroma/FAISS 오픈소스이며 로컬에서 실행 가능하여 초기 비용이 낮고 데이터 제어가 용이합니다. 커스터마이징의 자유도가 높습니다. 하지만 대규모 확장성 면에서는 Pinecone에 비해 제한적일 수 있습니다.\n",
    "\n",
    "선택은 프로젝트의 규모, 요구사항, 예산 등을 고려하여 결정해야 합니다. 대규모 프로덕션 환경에서는 Pinecone이 유리할 수 있지만, 소규모 프로젝트나 실험적인 환경에서는 Chroma나 Faiss가 더 적합할 수 있습니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- [Pinecone 공식 홈페이지](https://docs.pinecone.io/integrations/langchain)\n",
    "- [Pinecone 랭체인](https://python.langchain.com/v0.2/docs/integrations/vectorstores/pinecone/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH09-VectorStores\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH09-VectorStores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 업데이트 안내\n",
    "\n",
    "아래의 기능은 커스텀 구현한 내용이므로 아래의 라이브러리를 반드시 업데이트 후 진행해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-teddynote in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (0.3.45)\n",
      "Collecting langchain-teddynote\n",
      "  Downloading langchain_teddynote-0.4.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting anthropic>=0.64.0 (from langchain-teddynote)\n",
      "  Downloading anthropic-0.64.0-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: deepl>=1.22.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (1.22.0)\n",
      "Requirement already satisfied: feedparser>=6.0.11 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (6.0.11)\n",
      "Requirement already satisfied: kiwipiepy>=0.21.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (0.21.0)\n",
      "Requirement already satisfied: konlpy>=0.6.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (0.6.0)\n",
      "Requirement already satisfied: langchain-openai>=0.3.30 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (0.3.30)\n",
      "Requirement already satisfied: langchain>=0.3.27 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (0.3.27)\n",
      "Collecting langgraph>=0.6.5 (from langchain-teddynote)\n",
      "  Downloading langgraph-0.6.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: olefile>=0.47 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (0.47)\n",
      "Requirement already satisfied: openai>=1.99.9 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (1.99.9)\n",
      "Requirement already satisfied: pandas>=2.3.1 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (2.3.1)\n",
      "Requirement already satisfied: pdf2image>=1.17.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (1.17.0)\n",
      "Collecting pinecone-client>=6.0.0 (from langchain-teddynote)\n",
      "  Downloading pinecone_client-6.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: pinecone-text>=0.11.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (0.11.0)\n",
      "Requirement already satisfied: python-dotenv>=1.1.1 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (1.1.1)\n",
      "Requirement already satisfied: rank-bm25>=0.2.2 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (0.2.2)\n",
      "Requirement already satisfied: tavily-python>=0.7.10 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-teddynote) (0.7.10)\n",
      "Collecting twine>=6.1.0 (from langchain-teddynote)\n",
      "  Downloading twine-6.1.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from anthropic>=0.64.0->langchain-teddynote) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from anthropic>=0.64.0->langchain-teddynote) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from anthropic>=0.64.0->langchain-teddynote) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from anthropic>=0.64.0->langchain-teddynote) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from anthropic>=0.64.0->langchain-teddynote) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from anthropic>=0.64.0->langchain-teddynote) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from anthropic>=0.64.0->langchain-teddynote) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic>=0.64.0->langchain-teddynote) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic>=0.64.0->langchain-teddynote) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from httpx<1,>=0.25.0->anthropic>=0.64.0->langchain-teddynote) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic>=0.64.0->langchain-teddynote) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic>=0.64.0->langchain-teddynote) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic>=0.64.0->langchain-teddynote) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from pydantic<3,>=1.9.0->anthropic>=0.64.0->langchain-teddynote) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from deepl>=1.22.0->langchain-teddynote) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from requests<3,>=2->deepl>=1.22.0->langchain-teddynote) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from requests<3,>=2->deepl>=1.22.0->langchain-teddynote) (2.5.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from feedparser>=6.0.11->langchain-teddynote) (1.0.0)\n",
      "Requirement already satisfied: kiwipiepy_model<0.22,>=0.21 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from kiwipiepy>=0.21.0->langchain-teddynote) (0.21.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from kiwipiepy>=0.21.0->langchain-teddynote) (1.26.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from kiwipiepy>=0.21.0->langchain-teddynote) (4.67.1)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from konlpy>=0.6.0->langchain-teddynote) (1.6.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from konlpy>=0.6.0->langchain-teddynote) (5.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from JPype1>=0.7.0->konlpy>=0.6.0->langchain-teddynote) (24.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain>=0.3.27->langchain-teddynote) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain>=0.3.27->langchain-teddynote) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain>=0.3.27->langchain-teddynote) (0.4.14)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain>=0.3.27->langchain-teddynote) (2.0.43)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain>=0.3.27->langchain-teddynote) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.3.27->langchain-teddynote) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain>=0.3.27->langchain-teddynote) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain>=0.3.27->langchain-teddynote) (3.0.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.3.27->langchain-teddynote) (3.2.4)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langchain-openai>=0.3.30->langchain-teddynote) (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai>=0.3.30->langchain-teddynote) (2025.7.34)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langgraph>=0.6.5->langchain-teddynote) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langgraph>=0.6.5->langchain-teddynote) (0.6.4)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph>=0.6.5->langchain-teddynote)\n",
      "  Downloading langgraph_sdk-0.2.3-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langgraph>=0.6.5->langchain-teddynote) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph>=0.6.5->langchain-teddynote) (1.10.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph>=0.6.5->langchain-teddynote) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.3.27->langchain-teddynote) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from langsmith>=0.1.17->langchain>=0.3.27->langchain-teddynote) (0.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from pandas>=2.3.1->langchain-teddynote) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from pandas>=2.3.1->langchain-teddynote) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from pandas>=2.3.1->langchain-teddynote) (2025.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from pdf2image>=1.17.0->langchain-teddynote) (11.3.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from pinecone-client>=6.0.0->langchain-teddynote) (0.0.7)\n",
      "Requirement already satisfied: mmh3<5.0.0,>=4.1.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from pinecone-text>=0.11.0->langchain-teddynote) (4.1.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from pinecone-text>=0.11.0->langchain-teddynote) (3.9.1)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.25.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from pinecone-text>=0.11.0->langchain-teddynote) (2.32.4.20250809)\n",
      "Requirement already satisfied: click in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text>=0.11.0->langchain-teddynote) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->pinecone-text>=0.11.0->langchain-teddynote) (1.5.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.3.1->langchain-teddynote) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from tqdm->kiwipiepy>=0.21.0->langchain-teddynote) (0.4.6)\n",
      "Collecting readme-renderer>=35.0 (from twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading readme_renderer-44.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting keyring>=15.1 (from twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading keyring-25.6.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting rfc3986>=1.4.0 (from twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: rich>=12.0.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from twine>=6.1.0->langchain-teddynote) (14.1.0)\n",
      "Collecting id (from twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading id-1.5.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pywin32-ctypes>=0.2.0 (from keyring>=15.1->twine>=6.1.0->langchain-teddynote)\n",
      "  Using cached pywin32_ctypes-0.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: importlib_metadata>=4.11.4 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from keyring>=15.1->twine>=6.1.0->langchain-teddynote) (8.7.0)\n",
      "Collecting jaraco.classes (from keyring>=15.1->twine>=6.1.0->langchain-teddynote)\n",
      "  Using cached jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jaraco.functools (from keyring>=15.1->twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading jaraco_functools-4.3.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jaraco.context (from keyring>=15.1->twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from importlib_metadata>=4.11.4->keyring>=15.1->twine>=6.1.0->langchain-teddynote) (3.23.0)\n",
      "Collecting nh3>=0.2.14 (from readme-renderer>=35.0->twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading nh3-0.3.0-cp38-abi3-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting docutils>=0.21.2 (from readme-renderer>=35.0->twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading docutils-0.22-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: Pygments>=2.5.1 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from readme-renderer>=35.0->twine>=6.1.0->langchain-teddynote) (2.19.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from rich>=12.0.0->twine>=6.1.0->langchain-teddynote) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->twine>=6.1.0->langchain-teddynote) (0.1.2)\n",
      "Collecting more-itertools (from jaraco.classes->keyring>=15.1->twine>=6.1.0->langchain-teddynote)\n",
      "  Using cached more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting backports.tarfile (from jaraco.context->keyring>=15.1->twine>=6.1.0->langchain-teddynote)\n",
      "  Downloading backports.tarfile-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Downloading langchain_teddynote-0.4.4-py3-none-any.whl (59 kB)\n",
      "Downloading anthropic-0.64.0-py3-none-any.whl (297 kB)\n",
      "Downloading langgraph-0.6.6-py3-none-any.whl (153 kB)\n",
      "Downloading langgraph_sdk-0.2.3-py3-none-any.whl (52 kB)\n",
      "Downloading pinecone_client-6.0.0-py3-none-any.whl (6.7 kB)\n",
      "Downloading twine-6.1.0-py3-none-any.whl (40 kB)\n",
      "Downloading keyring-25.6.0-py3-none-any.whl (39 kB)\n",
      "Using cached pywin32_ctypes-0.2.3-py3-none-any.whl (30 kB)\n",
      "Downloading readme_renderer-44.0-py3-none-any.whl (13 kB)\n",
      "Downloading docutils-0.22-py3-none-any.whl (630 kB)\n",
      "   ---------------------------------------- 0.0/630.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 630.7/630.7 kB 23.0 MB/s eta 0:00:00\n",
      "Downloading nh3-0.3.0-cp38-abi3-win_amd64.whl (604 kB)\n",
      "   ---------------------------------------- 0.0/604.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 604.5/604.5 kB 21.4 MB/s eta 0:00:00\n",
      "Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading id-1.5.0-py3-none-any.whl (13 kB)\n",
      "Using cached jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
      "Downloading jaraco.context-6.0.1-py3-none-any.whl (6.8 kB)\n",
      "Downloading backports.tarfile-1.2.0-py3-none-any.whl (30 kB)\n",
      "Downloading jaraco_functools-4.3.0-py3-none-any.whl (10 kB)\n",
      "Using cached more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Installing collected packages: rfc3986, pywin32-ctypes, nh3, more-itertools, docutils, backports.tarfile, readme-renderer, pinecone-client, jaraco.functools, jaraco.context, jaraco.classes, id, langgraph-sdk, keyring, anthropic, twine, langgraph, langchain-teddynote\n",
      "\n",
      "   ---- -----------------------------------  2/18 [nh3]\n",
      "   -------- -------------------------------  4/18 [docutils]\n",
      "   -------- -------------------------------  4/18 [docutils]\n",
      "   -------- -------------------------------  4/18 [docutils]\n",
      "   -------- -------------------------------  4/18 [docutils]\n",
      "   ----------- ----------------------------  5/18 [backports.tarfile]\n",
      "  Attempting uninstall: pinecone-client\n",
      "   ----------- ----------------------------  5/18 [backports.tarfile]\n",
      "    Found existing installation: pinecone-client 3.2.2\n",
      "   ----------- ----------------------------  5/18 [backports.tarfile]\n",
      "    Uninstalling pinecone-client-3.2.2:\n",
      "   ----------- ----------------------------  5/18 [backports.tarfile]\n",
      "      Successfully uninstalled pinecone-client-3.2.2\n",
      "   ----------- ----------------------------  5/18 [backports.tarfile]\n",
      "   --------------- ------------------------  7/18 [pinecone-client]\n",
      "  Attempting uninstall: langgraph-sdk\n",
      "   --------------- ------------------------  7/18 [pinecone-client]\n",
      "    Found existing installation: langgraph-sdk 0.2.0\n",
      "   --------------- ------------------------  7/18 [pinecone-client]\n",
      "    Uninstalling langgraph-sdk-0.2.0:\n",
      "   --------------- ------------------------  7/18 [pinecone-client]\n",
      "      Successfully uninstalled langgraph-sdk-0.2.0\n",
      "   --------------- ------------------------  7/18 [pinecone-client]\n",
      "   -------------------------- ------------- 12/18 [langgraph-sdk]\n",
      "  Attempting uninstall: anthropic\n",
      "   -------------------------- ------------- 12/18 [langgraph-sdk]\n",
      "    Found existing installation: anthropic 0.63.0\n",
      "   -------------------------- ------------- 12/18 [langgraph-sdk]\n",
      "   ------------------------------- -------- 14/18 [anthropic]\n",
      "    Uninstalling anthropic-0.63.0:\n",
      "   ------------------------------- -------- 14/18 [anthropic]\n",
      "      Successfully uninstalled anthropic-0.63.0\n",
      "   ------------------------------- -------- 14/18 [anthropic]\n",
      "   ------------------------------- -------- 14/18 [anthropic]\n",
      "   ------------------------------- -------- 14/18 [anthropic]\n",
      "   ------------------------------- -------- 14/18 [anthropic]\n",
      "   ------------------------------- -------- 14/18 [anthropic]\n",
      "   ------------------------------- -------- 14/18 [anthropic]\n",
      "   --------------------------------- ------ 15/18 [twine]\n",
      "  Attempting uninstall: langgraph\n",
      "   --------------------------------- ------ 15/18 [twine]\n",
      "    Found existing installation: langgraph 0.6.4\n",
      "   --------------------------------- ------ 15/18 [twine]\n",
      "    Uninstalling langgraph-0.6.4:\n",
      "   --------------------------------- ------ 15/18 [twine]\n",
      "      Successfully uninstalled langgraph-0.6.4\n",
      "   --------------------------------- ------ 15/18 [twine]\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "  Attempting uninstall: langchain-teddynote\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "    Found existing installation: langchain-teddynote 0.3.45\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "    Uninstalling langchain-teddynote-0.3.45:\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "      Successfully uninstalled langchain-teddynote-0.3.45\n",
      "   ----------------------------------- ---- 16/18 [langgraph]\n",
      "   ---------------------------------------- 18/18 [langchain-teddynote]\n",
      "\n",
      "Successfully installed anthropic-0.64.0 backports.tarfile-1.2.0 docutils-0.22 id-1.5.0 jaraco.classes-3.4.0 jaraco.context-6.0.1 jaraco.functools-4.3.0 keyring-25.6.0 langchain-teddynote-0.4.4 langgraph-0.6.6 langgraph-sdk-0.2.3 more-itertools-10.7.0 nh3-0.3.0 pinecone-client-6.0.0 pywin32-ctypes-0.2.3 readme-renderer-44.0 rfc3986-2.0.0 twine-6.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# 업데이트 명령어\n",
    "!pip install -U langchain-teddynote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 처리를 위한 불용어 사전"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글 불용어 사전 가져오기 (추후 토크나이저에 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아',\n",
       " '휴',\n",
       " '아이구',\n",
       " '아이쿠',\n",
       " '아이고',\n",
       " '어',\n",
       " '나',\n",
       " '우리',\n",
       " '저희',\n",
       " '따라',\n",
       " '의해',\n",
       " '을',\n",
       " '를',\n",
       " '에',\n",
       " '의',\n",
       " '가',\n",
       " '으로',\n",
       " '로',\n",
       " '에게',\n",
       " '뿐이다']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_teddynote.korean import stopwords\n",
    "\n",
    "# 한글 불용어 사전 불러오기 (불용어 사전 출처: https://www.ranks.nl/stopwords/korean)\n",
    "stopword = stopwords()\n",
    "stopword[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리\n",
    "\n",
    "아래는 일반 문서의 전처리 과정입니다. `ROOT_DIR` 하위에 있는 모든 `.pdf` 파일을 읽어와 `document_lsit` 에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import glob\n",
    "\n",
    "# 텍스트 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "\n",
    "split_docs = []\n",
    "\n",
    "# 텍스트 파일을 load -> List[Document] 형태로 변환\n",
    "files = sorted(glob.glob(\"data/*.pdf\"))\n",
    "# files\n",
    "for file in files:\n",
    "    loader = PyMuPDFLoader(file)\n",
    "    split_docs.extend(loader.load_and_split(text_splitter))\n",
    "\n",
    "# 문서 개수 확인\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'등을 효과적으로 관리하는 데 필요한 기술적 지식이 요구된다. \\n둘째 클라우드 네이티브 아키텍처를 구현하기 위해서는 적절한 도구와 플랫폼을 선택해야 한다. 도커와 쿠버네티스 같은 \\n도구는 널리 사용되지만, 각 조직의 요구와 환경에 맞는 최적의 도구를 선택하는 것이 중요하다. 또한, 이러한 도구를 효과적 \\n으로 활용하기 위해서는 팀원들이 충분한 교육과 경험을 쌓아야 \\n한다. \\n마지막으로, 클라우드 네이티브 아키텍처는 문화적인 변화도 수반한다. 조직 내에서 팀 간의 협업을 촉진하고, 실패를 두려'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[127].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pinecone 에 DB 저장하기 위한 문서 전처리를 수행합니다. 이 과정에서 `metadata_keys` 를 지정할 수 있습니다.\n",
    "\n",
    "추가로 metadata 를 태깅하고 싶은 경우 사전 처리 작업에서 미리 metadata 를 추가한 뒤 진행합니다.\n",
    "\n",
    "- `split_docs`: 문서 분할 결과를 담은 List[Document] 입니다.\n",
    "- `metadata_keys`: 문서에 추가할 metadata 키를 담은 List 입니다.\n",
    "- `min_length`: 문서의 최소 길이를 지정합니다. 이 길이보다 짧은 문서는 제외합니다.\n",
    "- `use_basename`: 소스 경로를 기준으로 파일명을 사용할지 여부를 지정합니다. 기본값은 `False` 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Adobe Acrobat (64-bit) 25 Paper Capture Plug-in',\n",
       " 'creator': 'Hancom PDF 1.3.0.547',\n",
       " 'creationdate': '2025-08-25T10:42:33+09:00',\n",
       " 'source': 'data\\\\클라우드네이티브1-2.pdf',\n",
       " 'file_path': 'data\\\\클라우드네이티브1-2.pdf',\n",
       " 'total_pages': 2,\n",
       " 'format': 'PDF 1.6',\n",
       " 'title': '',\n",
       " 'author': 'park0',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2025-08-25T10:43:07+09:00',\n",
       " 'trapped': '',\n",
       " 'modDate': \"D:20250825104307+09'00'\",\n",
       " 'creationDate': \"D:20250825104233+09'00'\",\n",
       " 'page': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata 를 확인합니다.\n",
    "split_docs[127].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문서의 전처리\n",
    "\n",
    "- 필요한 `metadata` 정보를 추출합니다.\n",
    "- 최소 길이 이상의 데이만 필터링 합니다.\n",
    "  \n",
    "- 문서의 `basename` 을 사용할지 여부를 지정합니다. 기본값은 `False` 입니다.\n",
    "  - 여기서 `basename` 이란 파일 경로의 가장 마지막 부분을 의미합니다. \n",
    "  - 예를 들어, `/Users/teddy/data/document.pdf` 의 경우 `document.pdf` 가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Hancom PDF 1.3.0.542',\n",
       " 'creator': 'Hwp 2018 10.0.0.13462',\n",
       " 'creationdate': '2023-12-08T13:28:38+09:00',\n",
       " 'source': 'data\\\\SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_path': 'data\\\\SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'total_pages': 23,\n",
       " 'format': 'PDF 1.4',\n",
       " 'title': '',\n",
       " 'author': 'dj',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-12-08T13:28:38+09:00',\n",
       " 'trapped': '',\n",
       " 'modDate': \"D:20231208132838+09'00'\",\n",
       " 'creationDate': \"D:20231208132838+09'00'\",\n",
       " 'page': 0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023년 12월호'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1180d0fc254c7c9da859b2f017143a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import preprocess_documents\n",
    "\n",
    "contents, metadatas = preprocess_documents(     # preprocess_documents함수를 이용해 분할\n",
    "    split_docs=split_docs,\n",
    "    metadata_keys=[\"source\", \"page\", \"author\"],\n",
    "    min_length=5,\n",
    "    use_basename=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'SPRI_AI_Brief_2023년12월호_F.pdf']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use_basename=True 일 때, source 키에 파일명만 저장됩니다.(디렉토리를 제외됩니다.)\n",
    "metadatas[\"source\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023년 12월호',\n",
       " '2023년 12월호\\nⅠ. 인공지능 산업 동향 브리프\\n 1. 정책/법제 \\n   ▹ 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표  ························· 1\\n   ▹ G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의··························· 2\\n   ▹ 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언··························· 3',\n",
       " '▹ 미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각····································· 4\\n   ▹ 미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출················· 5\\n   ▹ EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항··················································· 6\\n \\n 2. 기업/산업',\n",
       " '2. 기업/산업 \\n   ▹ 미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성································ 7\\n   ▹ 코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개  ······································· 8\\n   ▹ 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································ 9',\n",
       " '▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··························································· 10\\n   ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\\n   ▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망··········································· 12']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VectorStore 에 저장할 문서 확인\n",
    "contents[:5]\n",
    "\n",
    "# list 타입의 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source', 'page', 'author'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VectorStore 에 저장할 metadata 확인\n",
    "metadatas.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'SPRI_AI_Brief_2023년12월호_F.pdf']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata 에서 source 를 확인합니다.\n",
    "metadatas[\"source\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 130, 130)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서 개수 확인, 소스 개수 확인, 페이지 개수 확인\n",
    "len(contents), len(metadatas[\"source\"]), len(metadatas[\"page\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API 키 발급\n",
    "\n",
    "- [링크](https://app.pinecone.io/)\n",
    "- 프로필 - Account - Projects - Starter - API keys - 발급\n",
    "\n",
    "`.env` 파일에 아래와 같이 추가합니다.\n",
    "\n",
    "```\n",
    "PINECONE_API_KEY=\"YOUR_PINECONE_API_KEY\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 VectorStore 인덱스 생성\n",
    "\n",
    "Pinecone 의 새로운 인덱스를 생성합니다.\n",
    "\n",
    "![pinecone-01.png](./images/pinecone-01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pinecone 인덱스를 생성합니다.\n",
    "\n",
    "**주의사항**\n",
    "- `metric` 은 유사도 측정 방법을 지정합니다. 만약 HybridSearch 를 고려하고 있다면 `metric` 은 `dotproduct` 로 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[create_index]\n",
      "{'dimension': 4096,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 0}},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_teddynote.community.pinecone import create_index\n",
    "\n",
    "# Pinecone 인덱스 생성\n",
    "pc_index = create_index(\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],\n",
    "    index_name=\"teddynote-db-index\",  # 인덱스 이름을 지정합니다.\n",
    "    dimension=4096,  # Embedding 차원과 맞춥니다. (OpenAIEmbeddings: 1536, UpstageEmbeddings: 4096)\n",
    "    metric=\"dotproduct\",  # 유사도 측정 방법을 지정합니다. (dotproduct, euclidean, cosine)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 **유료 Pod** 를 사용하는 예시입니다. **유료 Pod** 는 무료 Serverless Pod 대비 더 확장된 기능을 제공합니다.\n",
    "\n",
    "- 참고: https://docs.pinecone.io/guides/indexes/choose-a-pod-type-and-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유료 사용시 실행\n",
    "\n",
    "import os\n",
    "from langchain_teddynote.community.pinecone import create_index\n",
    "from pinecone import PodSpec\n",
    "\n",
    "# Pinecone 인덱스 생성\n",
    "pc_index = create_index(\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],\n",
    "    index_name=\"teddynote-db-index2\",  # 인덱스 이름을 지정합니다.\n",
    "    dimension=4096,  # Embedding 차원과 맞춥니다. (OpenAIEmbeddings: 1536, UpstageEmbeddings: 4096)\n",
    "    metric=\"dotproduct\",  # 유사도 측정 방법을 지정합니다. (dotproduct, euclidean, cosine)\n",
    "    pod_spec=PodSpec(   # cloud는 aws, gcp, azure 중 선택 가능 \n",
    "        environment=\"us-west1-gcp\", pod_type=\"p1.x1\", pods=1\n",
    "    ),  # 유료 Pod 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse Encoder 생성\n",
    "\n",
    "- Sparse Encoder 를 생성합니다. \n",
    "- `Kiwi Tokenizer` 와 한글 불용어(stopwords) 처리를 수행합니다.\n",
    "- Sparse Encoder 를 활용하여 contents 를 학습합니다. 여기서 학습한 인코드는 VectorStore 에 문서를 저장할 때 Sparse Vector 를 생성할 때 활용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import (\n",
    "    create_sparse_encoder,\n",
    "    fit_sparse_encoder,\n",
    ")\n",
    "\n",
    "# 한글 불용어 사전 + Kiwi 형태소 분석기를 사용합니다.\n",
    "# kiwi, okt, mecab, hannanum, komoran 중 선택 가능합니다.\n",
    "sparse_encoder = create_sparse_encoder(stopwords(), mode=\"kiwi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse Encoder 에 Corpus 를 학습합니다.\n",
    "\n",
    "- `save_path`: Sparse Encoder 를 저장할 경로입니다. 추후에 `pickle` 형식으로 저장한 Sparse Encoder 를 불러와 Query 임베딩할 때 사용합니다. 따라서, 이를 저장할 경로를 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed6a2494d354d7ab13332c0b43c34ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fit_sparse_encoder]\n",
      "Saved Sparse Encoder to: ./sparse_encoder.pkl\n"
     ]
    }
   ],
   "source": [
    "# Sparse Encoder 를 사용하여 contents 를 학습\n",
    "saved_path = fit_sparse_encoder(\n",
    "    sparse_encoder=sparse_encoder, contents=contents, save_path=\"./sparse_encoder.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[선택사항] 아래는 나중에 학습하고 저장한 Sparse Encoder 를 다시 불러와야 할 때 사용하는 코드입니다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import load_sparse_encoder\n",
    "\n",
    "# 추후에 학습된 sparse encoder 를 불러올 때 사용합니다.\n",
    "sparse_encoder = load_sparse_encoder(\"./sparse_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinecone: DB Index에 추가 (Upsert)\n",
    "\n",
    "![](./images/pinecone-02.png)\n",
    "\n",
    "- `context`: 문서의 내용입니다.\n",
    "- `page`: 문서의 페이지 번호입니다.\n",
    "- `source`: 문서의 출처입니다.\n",
    "- `values`: Embedder 를 통해 얻은 문서의 임베딩입니다.\n",
    "- `sparse values`: Sparse Encoder 를 통해 얻은 문서의 임베딩입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "# 임베딩 모델 생성\n",
    "openai_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "upstage_embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large-passage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산 처리를 하지 않고 배치 단위로 문서를 Upsert 합니다. 문서의 양이 많지 않다면 아래의 방식을 사용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38ac2d11c5546d495e146f5b152b7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[upsert_documents]\n",
      "{'dimension': 4096,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'teddynote-namespace-01': {'vector_count': 128}},\n",
      " 'total_vector_count': 128}\n",
      "CPU times: total: 2.14 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_teddynote.community.pinecone import upsert_documents\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "upsert_documents(\n",
    "    index=pc_index,  # Pinecone 인덱스\n",
    "    namespace=\"teddynote-namespace-01\",  # Pinecone namespace\n",
    "    contents=contents,  # 이전에 전처리한 문서 내용\n",
    "    metadatas=metadatas,  # 이전에 전처리한 문서 메타데이터\n",
    "    sparse_encoder=sparse_encoder,  # Sparse encoder\n",
    "    embedder=upstage_embeddings,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 분산처리를 수행하여 대용량 문서를 빠르게 Upsert 합니다. 대용량 업로드시 활용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from langchain_teddynote.community.pinecone import upsert_documents_parallel\n",
    "\n",
    "upsert_documents_parallel(\n",
    "    index=pc_index,  # Pinecone 인덱스\n",
    "    namespace=\"teddynote-namespace-02\",  # Pinecone namespace\n",
    "    contents=contents,  # 이전에 전처리한 문서 내용\n",
    "    metadatas=metadatas,  # 이전에 전처리한 문서 메타데이터\n",
    "    sparse_encoder=sparse_encoder,  # Sparse encoder\n",
    "    embedder=upstage_embeddings,\n",
    "    batch_size=64,\n",
    "    max_workers=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인덱스 조회/삭제\n",
    "\n",
    "`describe_index_stats` 메서드는 인덱스의 내용에 대한 통계 정보를 제공합니다. 이 메서드를 통해 네임스페이스별 벡터 수와 차원 수 등의 정보를 얻을 수 있습니다.\n",
    "\n",
    "**매개변수**\n",
    "* `filter` (Optional[Dict[str, Union[str, float, int, bool, List, dict]]]): 특정 조건에 맞는 벡터들에 대한 통계만 반환하도록 하는 필터. 기본값은 None\n",
    "* `**kwargs`: 추가 키워드 인자\n",
    "\n",
    "**반환값**\n",
    "* `DescribeIndexStatsResponse`: 인덱스에 대한 통계 정보를 담고 있는 객체\n",
    "\n",
    "**사용 예시**\n",
    "* 기본 사용: `index.describe_index_stats()`\n",
    "* 필터 적용: `index.describe_index_stats(filter={'key': 'value'})`\n",
    "\n",
    "**참고**\n",
    "- metadata 필터링은 유료 사용자에 한하여 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 4096,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'teddynote-namespace-01': {'vector_count': 130}},\n",
       " 'total_vector_count': 130}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 조회\n",
    "pc_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네임스페이스(namespace) 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네임스페이스 'teddynote-namespace-01'의 모든 데이터가 삭제되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.community.pinecone import delete_namespace\n",
    "\n",
    "delete_namespace(\n",
    "    pinecone_index=pc_index,\n",
    "    namespace=\"teddynote-namespace-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 4096,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 0}},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 유료 사용자 전용 기능입니다. 유료 사용자는 metadata 필터링을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import delete_by_filter\n",
    "\n",
    "# metadata 필터링(유료 기능) 으로 삭제\n",
    "delete_by_filter(\n",
    "    pinecone_index=pc_index,\n",
    "    namespace=\"teddynote-namespace-02\",\n",
    "    filter={\"source\": {\"$eq\": \"SPRi AI Brief_8월호_산업동향.pdf\"}},\n",
    ")\n",
    "pc_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검색기(Retriever) 생성\n",
    "\n",
    "### PineconeKiwiHybridRetriever 초기화 파라미터 설정\n",
    "\n",
    "`init_pinecone_index` 함수와 `PineconeKiwiHybridRetriever` 클래스는 Pinecone을 사용한 하이브리드 검색 시스템을 구현합니다. 이 시스템은 밀집 벡터와 희소 벡터를 결합하여 효과적인 문서 검색을 수행합니다.\n",
    "\n",
    "**Pinecone 인덱스 초기화**\n",
    "\n",
    "`init_pinecone_index` 함수는 Pinecone 인덱스를 초기화하고 필요한 구성 요소를 설정합니다.\n",
    "\n",
    "**매개변수**\n",
    "* `index_name` (str): Pinecone 인덱스 이름\n",
    "* `namespace` (str): 사용할 네임스페이스\n",
    "* `api_key` (str): Pinecone API 키\n",
    "* `sparse_encoder_pkl_path` (str): 희소 인코더 피클 파일 경로\n",
    "* `stopwords` (List[str]): 불용어 리스트\n",
    "* `tokenizer` (str): 사용할 토크나이저 (기본값: \"kiwi\")\n",
    "* `embeddings` (Embeddings): 임베딩 모델\n",
    "* `top_k` (int): 반환할 최대 문서 수 (기본값: 10)\n",
    "* `alpha` (float): 밀집 벡터와 희소 벡터의 가중치 조절 파라미터 (기본값: 0.5)\n",
    "\n",
    "**주요 기능**\n",
    "1. Pinecone 인덱스 초기화 및 통계 정보 출력\n",
    "2. 희소 인코더(BM25) 로딩 및 토크나이저 설정\n",
    "3. 네임스페이스 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U pinecone langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[init_pinecone_index]\n",
      "{'dimension': 4096,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'teddynote-namespace-01': {'vector_count': 130}},\n",
      " 'total_vector_count': 130}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_teddynote.korean import stopwords\n",
    "from langchain_teddynote.community.pinecone import init_pinecone_index\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "pinecone_params = init_pinecone_index(\n",
    "    index_name=\"teddynote-db-index\",  # Pinecone 인덱스 이름\n",
    "    namespace=\"teddynote-namespace-01\",  # Pinecone Namespace\n",
    "    api_key=os.environ[\"PINECONE_API_KEY\"],  # Pinecone API Key\n",
    "    sparse_encoder_path=\"./sparse_encoder.pkl\",  # Sparse Encoder 저장경로(save_path)\n",
    "    stopwords=stopwords(),  # 불용어 사전\n",
    "    tokenizer=\"kiwi\",\n",
    "    embeddings=UpstageEmbeddings(\n",
    "        model=\"solar-embedding-1-large-query\"\n",
    "    ),  # Dense Embedder\n",
    "    top_k=5,  # Top-K 문서 반환 개수\n",
    "    alpha=0.5,  # alpha=0.75로 설정한 경우, (0.75: Dense Embedding, 0.25: Sparse Embedding)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PineconeKiwiHybridRetriever\n",
    "\n",
    "`PineconeKiwiHybridRetriever` 클래스는 Pinecone과 Kiwi를 결합한 하이브리드 검색기를 구현합니다.\n",
    "\n",
    "**주요 속성**\n",
    "* `embeddings`: 밀집 벡터 변환용 임베딩 모델\n",
    "* `sparse_encoder`: 희소 벡터 변환용 인코더\n",
    "* `index`: Pinecone 인덱스 객체\n",
    "* `top_k`: 반환할 최대 문서 수\n",
    "* `alpha`: 밀집 벡터와 희소 벡터의 가중치 조절 파라미터\n",
    "* `namespace`: Pinecone 인덱스 내 네임스페이스\n",
    "\n",
    "**특징**\n",
    "* 밀집 벡터와 희소 벡터를 결합한 HybridSearch Retriever\n",
    "* 가중치 조절을 통한 검색 전략 최적화 가능\n",
    "* 다양한 동적 metadata 필터링 적용 가능(`search_kwargs` 사용: `filter`, `k`, `rerank`, `rerank_model`, `top_n` 등)\n",
    "\n",
    "**사용 예시**\n",
    "1. `init_pinecone_index` 함수로 필요한 구성 요소 초기화\n",
    "2. 초기화된 구성 요소로 `PineconeKiwiHybridRetriever` 인스턴스 생성\n",
    "3. 생성된 검색기를 사용하여 하이브리드 검색 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PineconeKiwiHybridRetriever` 를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.community.pinecone import PineconeKiwiHybridRetriever\n",
    "\n",
    "# 검색기 생성\n",
    "pinecone_retriever = PineconeKiwiHybridRetriever(**pinecone_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "{'author': 'dj', 'context': 'SPRi AI Brief |  \\n2023-12월호\\n10\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\nKEY Contents\\n£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원', 'page': 12.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf'}\n",
      "\n",
      "====================\n",
      "\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "{'author': 'dj', 'context': '£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \\n‘삼성 가우스’를 최초 공개\\n∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \\n최적화된 크기의 모델 선택이 가능\\n∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유', 'page': 12.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf'}\n",
      "\n",
      "====================\n",
      "\n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "{'author': 'dj', 'context': '어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\\n☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\\n삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\\nTechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.', 'page': 12.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf'}\n",
      "\n",
      "====================\n",
      "\n",
      "▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··························································· 10\n",
      "   ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\n",
      "   ▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망··········································· 12\n",
      "{'author': 'dj', 'context': '▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ··························································· 10\\n   ▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································ 11\\n   ▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망··········································· 12', 'page': 1.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf'}\n",
      "\n",
      "====================\n",
      "\n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \n",
      "처리를 지원\n",
      "{'author': 'dj', 'context': '온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\\n∙삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에 \\n단계적으로 탑재할 계획\\nn 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는 \\n이미지 모델의 3개 모델로 구성\\n∙언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의 \\n처리를 지원', 'page': 12.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf'}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "# search_results = pinecone_retriever.invoke(\"gpt-4o 미니 출시 관련 정보에 대해서 알려줘\")\n",
    "search_results = pinecone_retriever.invoke(\"삼성전자에서 자체 개발한 인공지능 모델의 이름은?\")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동적 `search_kwargs` 사용\n",
    "- `k`: 반환할 최대 문서 수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "{'author': 'dj', 'context': 'SPRi AI Brief |  \\n2023-12월호\\n10\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\nKEY Contents\\n£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원', 'page': 12.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf'}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    # \"gpt-4o 미니 출시 관련 정보에 대해서 알려줘\", search_kwargs={\"k\": 1}\n",
    "    \"삼성전자에서 자체 개발한 인공지능 모델의 이름은?\", search_kwargs={\"k\": 1}\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동적 `search_kwargs` 사용\n",
    "- `alpha`: 밀집 벡터와 희소 벡터의 가중치 조절 파라미터. 0과 1 사이의 값을 지정합니다. `0.5` 가 기본값이고, 1에 가까울수록 dense 벡터의 가중치가 높아집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "10\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "KEY Contents\n",
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "{'author': 'dj', 'context': 'SPRi AI Brief |  \\n2023-12월호\\n10\\n삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\\nn 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성 \\nAI 모델 ‘삼성 가우스’를 공개\\nn 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한 \\n삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\\nKEY Contents\\n£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원', 'page': 12.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf'}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    # \"앤스로픽\", search_kwargs={\"alpha\": 1, \"k\": 1}\n",
    "    \"삼성전자에서 자체 개발한 인공지능 모델의 이름은?\", search_kwargs={\"alpha\": 1, \"k\": 1}\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "{'author': 'dj', 'context': '£ 언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\\nn 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델 \\n‘삼성 가우스’를 최초 공개\\n∙정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에 \\n최적화된 크기의 모델 선택이 가능\\n∙삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며, \\n온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유', 'page': 12.0, 'source': 'SPRI_AI_Brief_2023년12월호_F.pdf'}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"삼성전자에서 자체 개발한 인공지능 모델의 이름은?\", search_kwargs={\"alpha\": 0, \"k\": 1}\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metadata 필터링**\n",
    "\n",
    "![](./images/pinecone-metadata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동적 `search_kwargs` 사용\n",
    "- `filter`: metadata 필터링 적용\n",
    "\n",
    "(예시) `page` 가 5보다 작은 문서만 검색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▹ 앤스로픽, 최신 AI 모델 ‘클로드 3.5 소네트’ 출시··························································· 10\n",
      "   ▹ 프랑스의 미스트랄AI, 6억 유로 규모의 투자 유치  ························································ 11\n",
      "{'author': 'dj', 'context': '▹ 앤스로픽, 최신 AI 모델 ‘클로드 3.5 소네트’ 출시··························································· 10\\n   ▹ 프랑스의 미스트랄AI, 6억 유로 규모의 투자 유치  ························································ 11', 'page': 1.0, 'source': 'SPRi AI Brief_7월호_산업동향.pdf'}\n",
      "\n",
      "====================\n",
      "\n",
      "2. 기업/산업 \n",
      "   ▹ 구글, 멀티모달 AI 모델 ‘제미나이’ 공개············································································  3\n",
      "   ▹ 구글 클라우드, 기업용 AI 플랫폼에 이미지 생성 AI ‘이매진 2’ 추가  ·························  4\n",
      "   ▹ 앤스로픽, 20만 개의 토큰을 입력할 수 있는 ‘클로드 2.1’ 공개 ···································  5\n",
      "{'author': 'dj', 'context': '2. 기업/산업 \\n   ▹ 구글, 멀티모달 AI 모델 ‘제미나이’ 공개············································································  3\\n   ▹ 구글 클라우드, 기업용 AI 플랫폼에 이미지 생성 AI ‘이매진 2’ 추가  ·························  4\\n   ▹ 앤스로픽, 20만 개의 토큰을 입력할 수 있는 ‘클로드 2.1’ 공개 ···································  5', 'page': 1.0, 'source': 'SPRi AI Brief_2024년1월호_F.pdf'}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽의 claude 출시 관련 내용을 알려줘\",\n",
    "    search_kwargs={\"filter\": {\"page\": {\"$lt\": 5}}, \"k\": 2},\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동적 `search_kwargs` 사용\n",
    "- `filter`: metadata 필터링 적용\n",
    "\n",
    "(예시) `source` 가 `SPRi AI Brief_8월호_산업동향.pdf` 문서내 검색합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앤트로픽의 클로드 하이쿠보다 높은 점수를 기록\n",
      "KEY Contents\n",
      "£ GPT-4o 미니, GPT-3.5 터보 대비 60% 이상 저렴하면서 성능은 우수\n",
      "n 오픈AI는 2024년 7월 28일 가장 비용 효율적인 소형 모델인 ‘GPT-4o 미니’를 출시하고 챗GPT에서 \n",
      "GPT-3.5를 대신해 무료 사용자 및 플러스와 팀 사용자에게 제공한다고 발표\n",
      "∙GPT-4o 미니는 입력 토큰 100만 개당 15센트, 출력 토큰 100만 개당 60센트로 가격이 책정되어, \n",
      "GPT-3.5 터보 대비 60% 이상 저렴\n",
      "{'author': 'dj', 'context': '앤트로픽의 클로드 하이쿠보다 높은 점수를 기록\\nKEY Contents\\n£ GPT-4o 미니, GPT-3.5 터보 대비 60% 이상 저렴하면서 성능은 우수\\nn 오픈AI는 2024년 7월 28일 가장 비용 효율적인 소형 모델인 ‘GPT-4o 미니’를 출시하고 챗GPT에서 \\nGPT-3.5를 대신해 무료 사용자 및 플러스와 팀 사용자에게 제공한다고 발표\\n∙GPT-4o 미니는 입력 토큰 100만 개당 15센트, 출력 토큰 100만 개당 60센트로 가격이 책정되어, \\nGPT-3.5 터보 대비 60% 이상 저렴', 'page': 13.0, 'source': 'SPRi AI Brief_8월호_산업동향.pdf'}\n",
      "\n",
      "====================\n",
      "\n",
      "1. 정책/법제  \n",
      "2. 기업/산업 \n",
      "3. 기술/연구 \n",
      " 4. 인력/교육\n",
      "11\n",
      "오픈AI, 비용 효율적인 소형 AI 모델 ‘GPT-4o 미니’ 출시\n",
      "n 오픈AI가 GPT-3.5 터보 대비 60% 이상 저렴한 소형 모델 ‘GPT-4o’ 미니를 발표했으며, 저렴한 \n",
      "비용과 낮은 지연 시간으로 다양한 애플리케이션에 활용될 것으로 기대\n",
      "n GPT-4o는 주요 벤치마크에서 GPT-3.5를 앞섰으며, 경쟁 소형 모델인 구글의 제미나이 플래시와 \n",
      "앤트로픽의 클로드 하이쿠보다 높은 점수를 기록\n",
      "KEY Contents\n",
      "{'author': 'dj', 'context': '1. 정책/법제  \\n2. 기업/산업 \\n3. 기술/연구 \\n 4. 인력/교육\\n11\\n오픈AI, 비용 효율적인 소형 AI 모델 ‘GPT-4o 미니’ 출시\\nn 오픈AI가 GPT-3.5 터보 대비 60% 이상 저렴한 소형 모델 ‘GPT-4o’ 미니를 발표했으며, 저렴한 \\n비용과 낮은 지연 시간으로 다양한 애플리케이션에 활용될 것으로 기대\\nn GPT-4o는 주요 벤치마크에서 GPT-3.5를 앞섰으며, 경쟁 소형 모델인 구글의 제미나이 플래시와 \\n앤트로픽의 클로드 하이쿠보다 높은 점수를 기록\\nKEY Contents', 'page': 13.0, 'source': 'SPRi AI Brief_8월호_산업동향.pdf'}\n",
      "\n",
      "====================\n",
      "\n",
      "KEY Contents\n",
      "£ 제미나이 1.5 플래시, GPT-3.5 터보 대비 속도 40% 향상 및 비용은 4배 저렴\n",
      "n 구글이 2024년 6월 28일 ‘제미나이 1.5 프로’ 모델의 컨텍스트 창을 200만 개 토큰으로 확장하는 \n",
      "한편, 제미나이 1.5 프로보다 속도를 개선한 ‘제미나이 1.5 플래시’를 정식 출시\n",
      "∙구글은 2024년 5월 I/O에서 대기자 명단을 받아 제미나이 1.5 프로에서 200만 개 토큰 컨텍스트 창*을 \n",
      "제공하다가 이번 발표로 모든 개발자로 대상을 확대\n",
      "{'author': 'dj', 'context': 'KEY Contents\\n£ 제미나이 1.5 플래시, GPT-3.5 터보 대비 속도 40% 향상 및 비용은 4배 저렴\\nn 구글이 2024년 6월 28일 ‘제미나이 1.5 프로’ 모델의 컨텍스트 창을 200만 개 토큰으로 확장하는 \\n한편, 제미나이 1.5 프로보다 속도를 개선한 ‘제미나이 1.5 플래시’를 정식 출시\\n∙구글은 2024년 5월 I/O에서 대기자 명단을 받아 제미나이 1.5 프로에서 200만 개 토큰 컨텍스트 창*을 \\n제공하다가 이번 발표로 모든 개발자로 대상을 확대', 'page': 12.0, 'source': 'SPRi AI Brief_8월호_산업동향.pdf'}\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 실행 결과\n",
    "search_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽의 claude 3.5 출시 관련 내용을 알려줘\",\n",
    "    search_kwargs={\n",
    "        \"filter\": {\"source\": {\"$eq\": \"SPRi AI Brief_8월호_산업동향.pdf\"}},\n",
    "        \"k\": 3,\n",
    "    },\n",
    ")\n",
    "for result in search_results:\n",
    "    print(result.page_content)\n",
    "    print(result.metadata)\n",
    "    print(\"\\n====================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reranking 적용\n",
    "\n",
    "- 동적 reranking 기능을 구현해 놓았지만, pinecone 라이브러리 의존성에 문제가 있을 수 있습니다.\n",
    "- 따라서, 아래 코드는 향후 의존성 해결 후 원활하게 동작할 수 있습니다.\n",
    "\n",
    "참고 문서: https://docs.pinecone.io/guides/inference/rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reranker 미사용\n",
    "retrieval_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽의 클로드 소넷\",\n",
    ")\n",
    "\n",
    "# BGE-reranker-v2-m3 모델 사용\n",
    "reranked_results = pinecone_retriever.invoke(\n",
    "    \"앤스로픽의 클로드 소넷\",\n",
    "    search_kwargs={\"rerank\": True, \"rerank_model\": \"bge-reranker-v2-m3\", \"top_n\": 3},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Retrieval]\n",
      "1. 정책/법제  \n",
      "2. 기업/산업 \n",
      "3. 기술/연구 \n",
      " 4. 인력/교육\n",
      "9\n",
      "앤스로픽, 최신 AI 모델 ‘클로드 3.5 소네트’ 출시 \n",
      "n 앤스로픽이 최신 AI 모델 ‘클로드 3.5 소네트’을 공개하고 이전 모델 중 가장 고성능 모델인 \n",
      "‘클로드 3 오퍼스’나 오픈AI의 최신 모델 ‘GPT-4o’보다 성능이 뛰어나다고 강조\n",
      "n 앤스로픽은 클로드로 생성한 코딩이나 문서 등을 실시간으로 확인해 편집과 같은 작업을 할 수 \n",
      "있는 ‘아티팩트’ 신기능도 출시\n",
      "KEY Contents\n",
      "\n",
      "------------------\n",
      "\n",
      "[Reranked] rerank_score:  0.99635005\n",
      "1. 정책/법제  \n",
      "2. 기업/산업 \n",
      "3. 기술/연구 \n",
      " 4. 인력/교육\n",
      "9\n",
      "앤스로픽, 최신 AI 모델 ‘클로드 3.5 소네트’ 출시 \n",
      "n 앤스로픽이 최신 AI 모델 ‘클로드 3.5 소네트’을 공개하고 이전 모델 중 가장 고성능 모델인 \n",
      "‘클로드 3 오퍼스’나 오픈AI의 최신 모델 ‘GPT-4o’보다 성능이 뛰어나다고 강조\n",
      "n 앤스로픽은 클로드로 생성한 코딩이나 문서 등을 실시간으로 확인해 편집과 같은 작업을 할 수 \n",
      "있는 ‘아티팩트’ 신기능도 출시\n",
      "KEY Contents\n",
      "\n",
      "====================\n",
      "\n",
      "[Retrieval]\n",
      "▹ 앤스로픽, 최신 AI 모델 ‘클로드 3.5 소네트’ 출시··························································· 10\n",
      "   ▹ 프랑스의 미스트랄AI, 6억 유로 규모의 투자 유치  ························································ 11\n",
      "\n",
      "------------------\n",
      "\n",
      "[Reranked] rerank_score:  0.9956346\n",
      "있는 ‘아티팩트’ 신기능도 출시\n",
      "KEY Contents\n",
      "£ 클로드 3.5 소네트, 이전 대표모델 클로드 3 오퍼스와 오픈AI의 GPT-4o 능가\n",
      "n 앤스로픽이 2024년 6월 21일 ‘클로드(Claude) 3.5’ 모델군 중 첫 번째로 ‘소네트(Sonnet)’를 공개\n",
      "했으며, 하반기에 경량 모델 ‘하이쿠(Haiku)’와 가장 강력한 ‘오퍼스(Opus)’를 출시할 계획\n",
      "∙소네트는 클로드 웹사이트(Claude.ai) 및 iOS 앱에서 무료로 제공되며, 유료 가입자에게는 이용 \n",
      "한도를 대폭 넓혀서 제공\n",
      "\n",
      "====================\n",
      "\n",
      "[Retrieval]\n",
      "1. 정책/법제  \n",
      "2. 기업/산업 \n",
      "3. 기술/연구 \n",
      " 4. 인력/교육\n",
      "앤스로픽, 20만 개의 토큰을 입력할 수 있는 ‘클로드 2.1’ 공개  \n",
      "n 앤스로픽이 최대 20만 개의 토큰 입력을 지원하고 환각 현상을 두 배 줄인 ‘클로드 2.1’ 버전을 \n",
      "공개했으며, 20만 개의 토큰 입력은 유료 버전인 ‘클로드 프로’에서만 제공\n",
      "n 클로드 2.1은 베타 버전의 도구 기능을 도입하여, 사용자가 API를 연결하는 방식으로 복잡한 수치 \n",
      "추론을 위한 계산기 사용이나 웹 검색을 이용한 질의 답변 등 다양한 작업을 수행 가능하도록 지원\n",
      "\n",
      "------------------\n",
      "\n",
      "[Reranked] rerank_score:  0.94240075\n",
      "▹ 앤스로픽, 최신 AI 모델 ‘클로드 3.5 소네트’ 출시··························································· 10\n",
      "   ▹ 프랑스의 미스트랄AI, 6억 유로 규모의 투자 유치  ························································ 11\n",
      "\n",
      "====================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retrieval_results 와 reranked_results 를 비교합니다.\n",
    "for res1, res2 in zip(retrieval_results, reranked_results):\n",
    "    print(\"[Retrieval]\")\n",
    "    print(res1.page_content)\n",
    "    print(\"\\n------------------\\n\")\n",
    "    print(\"[Reranked] rerank_score: \", res2.metadata[\"rerank_score\"])\n",
    "    print(res2.page_content)\n",
    "    print(\"\\n====================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-Us6BDj1P-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
