{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8382978f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# LlamaParser\n",
    " \n",
    "LlamaParse는 LlamaIndex에서 개발한 문서 파싱 서비스로, 대규모 언어 모델(LLM)을 위해 특별히 설계되었습니다. 주요 특징은 다음과 같습니다:\n",
    "\n",
    "- PDF, Word, PowerPoint, Excel 등 다양한 문서 형식 지원\n",
    "- 자연어 지시를 통한 맞춤형 출력 형식 제공\n",
    "- 복잡한 표와 이미지 추출 기능\n",
    "- JSON 모드 지원\n",
    "- 외국어 지원\n",
    "\n",
    "LlamaParse는 독립형 API로 제공되며, LlamaCloud 플랫폼의 일부로도 사용 가능합니다. 이 서비스는 문서를 파싱하고 정제하여 검색 증강 생성(RAG) 등 LLM 기반 애플리케이션의 성능을 향상시키는 것을 목표로 합니다.\n",
    "\n",
    "사용자는 무료로 하루 1,000페이지를 처리할 수 있으며, 유료 플랜을 통해 추가 용량을 확보할 수 있습니다. LlamaParse는 현재 공개 베타 버전으로 제공되고 있으며, 지속적으로 기능이 확장되고 있습니다.\n",
    "\n",
    "- 링크: https://cloud.llamaindex.ai\n",
    "\n",
    "**API 키 설정**\n",
    "- API 키를 발급 후 `.env` 파일에 `LLAMA_CLOUD_API_KEY` 에 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de92eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install llama-index-core llama-parse llama-index-readers-file python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850910e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "nest_asyncio.apply()    # Jupyter Notebook 환경에서 비동기 함수 실행을 위해 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "828427a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.getenv(\"LLAMA_CLOUD_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ff3b85",
   "metadata": {},
   "source": [
    "기본 파서 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a94cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 4afe836a-d9cf-4080-a9b9-8997db7042c7\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# 파서 설정\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",  # \"markdown\"과 \"text\" 사용 가능\n",
    "    num_workers=8,  # worker 수 (기본값: 4) # os에서 인식되는 코어의 갯수를 llama parser에 전달\n",
    "    verbose=True,   # 처리 과정을 출력\n",
    "    language=\"ko\",  # 출력되는 언어를 한국어로 설정 (기본값: \"en\")\n",
    ")\n",
    "\n",
    "# SimpleDirectoryReader를 사용하여 파일 파싱\n",
    "file_extractor = {\".pdf\": parser}\n",
    "\n",
    "# LlamaParse로 파일 파싱\n",
    "documents = SimpleDirectoryReader(  # 여러 개의 파일을 동시에 읽을수 있게 해줌.\n",
    "    input_files=[\"data/SPRI_AI_Brief_2023년12월호_F.pdf\"],\n",
    "    file_extractor=file_extractor,\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f4aabfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 페이지 수 확인\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a08fb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='24c3d47a-98fd-47a5-841b-9f2e562ac10e', embedding=None, metadata={'file_path': 'data\\\\SPRI_AI_Brief_2023년12월호_F.pdf', 'file_name': 'SPRI_AI_Brief_2023년12월호_F.pdf', 'file_type': 'application/pdf', 'file_size': 975735, 'creation_date': '2025-08-21', 'last_modified_date': '2025-08-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='# 2023년 12월호\\n\\n# 인공지능 산업의 최신 동향\\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179d4e1b",
   "metadata": {},
   "source": [
    "LlamaIndex -> LangChain Document 로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10be578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭체인 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4db68c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표\n",
      "\n",
      "# KEY Contents\n",
      "\n",
      "- 미국 바이든 대통령이 ‘안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령’에 서명하고 광범위한 행정 조치를 명시\n",
      "- 행정명령은 △AI의 안전과 보안 기준 마련 △개인정보보호 △형평성과 시민권 향상 △소비자 보호 △노동자 지원 △혁신과 경쟁 촉진 △국제협력을 골자로 함\n",
      "\n",
      "# 바이든 대통령, AI 행정명령 통해 안전하고 신뢰할 수 있는 AI 개발과 활용 추진\n",
      "\n",
      "- 미국 바이든 대통령이 2023년 10월 30일 연방정부 차원에서 안전하고 신뢰할 수 있는 AI 개발과 사용을 보장하기 위한 행정명령을 발표\n",
      "- 행정명령은 △AI의 안전과 보안 기준 마련 △개인정보보호 △형평성과 시민권 향상 △소비자 보호 △노동자 지원 △혁신과 경쟁 촉진 △국제협력에 관한 내용을 포괄\n",
      "\n",
      "# (AI 안전과 보안 기준)\n",
      "\n",
      "- 강력한 AI 시스템을 개발하는 기업에게 안전 테스트 결과와 시스템에 관한 주요 정보를 미국 정부와 공유할 것을 요구하고, AI 시스템의 안전성과 신뢰성 확인을 위한 표준 및 AI 생성 콘텐츠 표시를 위한 표준과 모범사례 확립을 추진\n",
      "- △10²⁶ 플롭스(FLOPS, Floating Point Operation Per Second)를 초과하는 컴퓨팅 성능 또는 생물학적 서열 데이터를 주로 사용하고 10²³플롭스를 초과하는 컴퓨팅 성능을 사용하는 모델\n",
      "- △단일 데이터센터에서 1,000Gbit/s 이상의 네트워킹으로 연결되며 AI 훈련에서 이론상 최대 10²⁰ 플롭스를 처리할 수 있는 컴퓨팅 용량을 갖춘 컴퓨팅 클러스터가 정보공유 요구대상\n",
      "\n",
      "# (형평성과 시민권 향상)\n",
      "\n",
      "- 법률, 주택, 보건 분야에서 AI의 무책임한 사용으로 인한 차별과 편견 및 기타 문제를 방지하는 조치를 확대\n",
      "- 형사사법 시스템에서 AI 사용 모범사례를 개발하고, 주택 임대 시 AI 알고리즘 차별을 막기 위한 명확한 지침을 제공하며, 보건복지 부문에서 책임 있는 AI 배포와 사용을 위한 전략을 마련\n",
      "\n",
      "# (소비자 보호와 근로자 지원)\n",
      "\n",
      "- 의료 분야에서 책임 있는 AI 사용을 촉진하고 맞춤형 개인교습 등 학교 내 AI 교육 도구 관련 자원을 개발하며, AI로 인한 근로자 피해를 완화하고 이점을 극대화하는 원칙과 모범사례를 마련\n",
      "\n",
      "# (혁신과 경쟁 촉진)\n",
      "\n",
      "- 국가AI연구자원(National Artificial Intelligence Research Resource, NAIRR)*을 통해 미국 전역의 AI 연구를 촉진하고, 중소기업과 개발자에 기술과 인프라를 지원\n",
      "- * 국가 차원에서 AI 연구 인프라를 확충해 더 많은 AI 연구자에게 인프라를 지원하는 프로그램\n",
      "- 비자 기준과 인터뷰 절차의 현대화와 간소화로 AI 관련 주요 분야의 전문 지식을 갖춘 외국인들이 미국에서 공부하고 취업할 수 있도록 지원\n",
      "\n",
      "☞ 출처 : The White House, Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence (E.O. 14110), 2023.10.30.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89ec141f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_path': 'data\\\\SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_name': 'SPRI_AI_Brief_2023년12월호_F.pdf',\n",
       " 'file_type': 'application/pdf',\n",
       " 'file_size': 975735,\n",
       " 'creation_date': '2025-08-21',\n",
       " 'last_modified_date': '2025-08-21'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata 출력\n",
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845a3bc",
   "metadata": {},
   "source": [
    "## MultiModal Model 로 파싱\n",
    "\n",
    "**주요 파라미터**\n",
    "\n",
    "- `use_vendor_multimodal_model`: 멀티모달 모델 사용 여부를 지정합니다. `True`로 설정하면 외부 벤더의 멀티모달 모델을 사용합니다.\n",
    "\n",
    "- `vendor_multimodal_model_name`: 사용할 멀티모달 모델의 이름을 지정합니다. 여기서는 \"openai-gpt4o\"를 사용하고 있습니다.\n",
    "\n",
    "- `vendor_multimodal_api_key`: 멀티모달 모델 API 키를 지정합니다. 환경 변수에서 OpenAI API 키를 가져옵니다.\n",
    "\n",
    "- `result_type`: 파싱 결과의 형식을 지정합니다. \"markdown\"으로 설정되어 있어 결과가 마크다운 형식으로 반환됩니다.\n",
    "\n",
    "- `language`: 파싱할 문서의 언어를 지정합니다. \"ko\"로 설정되어 한국어로 처리됩니다.\n",
    "\n",
    "- `skip_diagonal_text`: 대각선 텍스트를 건너뛸지 여부를 결정합니다.\n",
    "\n",
    "- `page_separator`: 페이지 구분자를 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f03fc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "    vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    # skip_diagonal_text=True,\n",
    "    # page_separator=\"\\n=================\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04c986f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id aaffdde2-af24-4e28-9d24-96a7bfc656b1\n"
     ]
    }
   ],
   "source": [
    "# parsing 된 결과\n",
    "parsed_docs = documents.load_data(file_path=\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55bb48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbe71f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# SPRi AI Brief\n",
      "\n",
      "인공지능 산업의 최신 동향\n",
      "\n",
      "2023년 12월호\n",
      "\n",
      "소프트웨어정책연구소  \n",
      "Software Policy & Research Institute\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc038703",
   "metadata": {},
   "source": [
    "아래와 같이 사용자 정의 인스트럭션을 지정하는 것도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2863efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: parsing_instruction is deprecated. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "Started parsing the file under job_id 7796804f-1545-46bd-8e6d-d2c660b1469e\n"
     ]
    }
   ],
   "source": [
    "# parsing instruction 을 지정합니다.\n",
    "parsing_instruction = (\n",
    "    \"You are parsing a brief of AI Report. Please extract tables in markdown format.\"\n",
    ")\n",
    "\n",
    "# LlamaParse 설정\n",
    "parser = LlamaParse(\n",
    "    use_vendor_multimodal_model=True,\n",
    "    vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "    vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    result_type=\"markdown\",\n",
    "    language=\"ko\",\n",
    "    parsing_instruction=parsing_instruction,\n",
    ")\n",
    "\n",
    "# parsing 된 결과\n",
    "parsed_docs = parser.load_data(file_path=\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
    "\n",
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d87bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown 형식으로 추출된 테이블 확인\n",
    "print(docs[-2].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500b2845",
   "metadata": {},
   "source": [
    "### Llama Parser 함수 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e7c6d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id 554aa287-b0ca-4c88-89df-ca8fde50e826\n",
      "✅ 파일 저장 완료: data/2103.15348v2.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = \"data/2103.15348v2.pdf\"\n",
    "parsed_docs = documents.load_data(file_path=file_path)  # 문서 로드\n",
    "\n",
    "# langchain 도큐먼트로 변환\n",
    "docs = [doc.to_langchain_format() for doc in parsed_docs]   # langchain 포맷으로 변환 // 과금 요소가 있으므로 확인!\n",
    "\n",
    "# os.path.splitext()를 사용하여 경로와 확장자를 분리하고, 새로운 확장자를 붙입니다.\n",
    "# file_root는 'data/2103.15348v2'가 됩니다.\n",
    "file_root, _ = os.path.splitext(file_path)\n",
    "output_file_path = file_root + \".md\"\n",
    "\n",
    "# 1. 모든 페이지의 page_content를 리스트로 추출합니다.\n",
    "#    각 페이지 사이를 두 줄 띄어쓰기(\\n\\n)로 구분하여 가독성을 높입니다.\n",
    "full_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# 2. 추출한 전체 텍스트를 파일에 저장합니다.\n",
    "#    'w' 모드는 파일을 쓰기 모드로 열며, encoding='utf-8'은 한글 깨짐을 방지합니다.\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(full_text)\n",
    "\n",
    "print(f\"✅ 파일 저장 완료: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1cd110f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 './data/비뢰도.txt' 파일 파싱을 시작합니다...\n",
      "Started parsing the file under job_id 35045f77-9d51-40ca-8489-1df6d3beb47f\n",
      "✅ 파일 저장 완료: ./data/비뢰도.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = LlamaParse(result_type=\"markdown\")\n",
    "\n",
    "\n",
    "def pdf_parser(pdf_file_path: str):\n",
    "    \"\"\"\n",
    "    PDF 파일을 파싱하여 그 내용을 Markdown 파일로 저장합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_file_path (str): 처리할 PDF 파일의 경로.\n",
    "    \"\"\"\n",
    "    print(f\"🔄 '{pdf_file_path}' 파일 파싱을 시작합니다...\")\n",
    "\n",
    "    try:\n",
    "        # parsing instruction 을 지정합니다.\n",
    "        parsing_instruction = (\n",
    "            \"You are parsing a AI Report. Please extract tables in markdown format.\"\n",
    "        )\n",
    "\n",
    "        # LlamaParse 설정\n",
    "        parser = LlamaParse(\n",
    "            use_vendor_multimodal_model=True,\n",
    "            vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "            vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            result_type=\"markdown\",\n",
    "            high_res_ocr=True,\n",
    "            # parsing_mode=\"Unstructured\",  # 지금은 안써도 무방\n",
    "            language=\"ko\",\n",
    "            parsing_instruction=parsing_instruction,\n",
    "        )\n",
    "\n",
    "        # 1. LlamaParse를 사용하여 PDF 파일을 로드합니다.\n",
    "        # 'documents' 객체는 이 함수 외부에서 미리 정의되어 있어야 합니다.\n",
    "        parsed_docs = documents.load_data(file_path=pdf_file_path)\n",
    "\n",
    "        # 2. LangChain 형식의 도큐먼트로 변환합니다.\n",
    "        docs = [doc.to_langchain_format() for doc in parsed_docs]\n",
    "\n",
    "        # 3. 저장할 Markdown 파일의 경로를 생성합니다. (확장자 변경)\n",
    "        file_root, _ = os.path.splitext(pdf_file_path)\n",
    "        output_file_path = file_root + \".md\"\n",
    "\n",
    "        # 4. 모든 페이지의 내용을 하나의 텍스트로 합칩니다.\n",
    "        #    페이지 사이는 두 줄로 띄어 가독성을 높입니다.\n",
    "        full_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "        # 5. 추출된 전체 텍스트를 .md 파일로 저장합니다.\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(full_text)\n",
    "\n",
    "        print(f\"✅ 파일 저장 완료: {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 오류: 파일을 찾을 수 없습니다 - {pdf_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n",
    "\n",
    "\n",
    "# --- 함수 사용 예시 ---\n",
    "# 이 코드를 실행하기 전에 'documents' 파서 객체를 초기화해야 합니다.\n",
    "# file_to_parse = \"data/디지털정부혁신추진계획.pdf\"\n",
    "# file_to_parse = \"./data/클라우드네이티브1-2.pdf\"\n",
    "# file_to_parse = \"./data/클라우드네이티브_일부2.pdf\"\n",
    "# file_to_parse = \"./data/클라우드네이티브1-3.pdf\"\n",
    "# file_to_parse = \"./data/sample-word-document.docx\"\n",
    "# file_to_parse = \"./data/디지털정부혁신추진계획.hwp\"\n",
    "file_to_parse = \"./data/비뢰도.txt\"\n",
    "\n",
    "\n",
    "pdf_parser(file_to_parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6597b",
   "metadata": {},
   "source": [
    "### 클라우드네이티브1-2.pdf\n",
    "-> 생성된 파일과 원본을 비교한 결과, 페이지 변경으로 인해 문장이 끊어지는 부분에서 멋대로 내용을 추론하여 생성함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa426a",
   "metadata": {},
   "source": [
    "### 클라우드네이티브1-3.pdf\n",
    "\n",
    "high_res_ocr=True를 추가했을때,\n",
    "-> 생성된 파일을 확인한 결과 OCR 인식을 하지 못함.?\n",
    "-> 아래는  gemini에게 요청해 수정한 코드인데 실행 결과 정상적으로 인식을 했음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a8e0d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 './data/클라우드네이티브1-3.pdf' 파일 파싱을 시작합니다...\n",
      "WARNING: parsing_instruction is deprecated. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "Started parsing the file under job_id e490b7d4-b89f-45aa-85f1-da3cc4bf4e2a\n",
      "✅ 파일 저장 완료: ./data/클라우드네이티브1-3.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# 전역 변수 'documents' 정의는 불필요하므로 삭제합니다.\n",
    "# documents = LlamaParse(result_type=\"markdown\") # 이 줄을 삭제하세요.\n",
    "\n",
    "def pdf_parser(pdf_file_path: str):\n",
    "    \"\"\"\n",
    "    PDF 파일을 파싱하여 그 내용을 Markdown 파일로 저장합니다.\n",
    "\n",
    "    Args:\n",
    "        pdf_file_path (str): 처리할 PDF 파일의 경로.\n",
    "    \"\"\"\n",
    "    print(f\"🔄 '{pdf_file_path}' 파일 파싱을 시작합니다...\")\n",
    "\n",
    "    try:\n",
    "        # 1. parsing instruction 을 지정합니다.\n",
    "        parsing_instruction = (\n",
    "            \"You are parsing a AI Report. Please extract tables in markdown format.\"\n",
    "        )\n",
    "\n",
    "        # 2. LlamaParse 설정 (설정을 지정한 parser 객체를 만듭니다.)\n",
    "        parser = LlamaParse(\n",
    "            use_vendor_multimodal_model=True,\n",
    "            vendor_multimodal_model_name=\"openai-gpt4o\",\n",
    "            vendor_multimodal_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "            result_type=\"markdown\",\n",
    "            high_res_ocr=True,\n",
    "            # parsing_mode=\"Unstructured\",  # 지금은 안써도 무방\n",
    "            language=\"ko\",\n",
    "            parsing_instruction=parsing_instruction,\n",
    "        )\n",
    "\n",
    "        # 3. LlamaParse를 사용하여 PDF 파일을 로드합니다.\n",
    "        #    ***여기서 'parser' 객체를 사용합니다.***\n",
    "        parsed_docs = parser.load_data(file_path=pdf_file_path)\n",
    "\n",
    "        # 4. LangChain 형식의 도큐먼트로 변환합니다.\n",
    "        docs = [doc.to_langchain_format() for doc in parsed_docs]\n",
    "\n",
    "        # 5. 저장할 Markdown 파일의 경로를 생성합니다.\n",
    "        file_root, _ = os.path.splitext(pdf_file_path)\n",
    "        output_file_path = file_root + \".md\"\n",
    "\n",
    "        # 6. 모든 페이지의 내용을 하나의 텍스트로 합칩니다.\n",
    "        full_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "        # 7. 추출된 전체 텍스트를 .md 파일로 저장합니다.\n",
    "        with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(full_text)\n",
    "\n",
    "        print(f\"✅ 파일 저장 완료: {output_file_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 오류: 파일을 찾을 수 없습니다 - {pdf_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류 발생: {e}\")\n",
    "\n",
    "\n",
    "# --- 함수 사용 예시 ---\n",
    "file_to_parse = \"./data/클라우드네이티브1-3.pdf\"\n",
    "\n",
    "pdf_parser(file_to_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b586c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-Us6BDj1P-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
