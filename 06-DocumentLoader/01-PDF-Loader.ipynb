{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66f34be",
   "metadata": {},
   "source": [
    "# PDF\n",
    "\n",
    "[Portable Document Format (PDF)](https://en.wikipedia.org/wiki/PDF), ISO 32000으로 표준화된 파일 형식은 Adobe가 1992년에 문서를 제시하기 위해 개발했으며, 이는 응용 소프트웨어, 하드웨어 및 운영 시스템에 독립적인 방식으로 텍스트 서식 및 이미지를 포함합니다.\n",
    "\n",
    "이 가이드는 `PDF` 문서를 LangChain [Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) 형식으로 로드하는 방법을 다룹니다. 이 형식은 다운스트림에서 사용됩니다.\n",
    "\n",
    "LangChain은 다양한 PDF 파서와 통합됩니다. 일부는 간단하고 상대적으로 저수준이며, 다른 일부는 OCR 및 이미지 처리를 지원하거나 고급 문서 레이아웃 분석을 수행합니다. \n",
    "\n",
    "올바른 선택은 사용자의 애플리케이션에 따라 달라집니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- [LangChain 도큐먼트](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/pdf/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3883eda",
   "metadata": {},
   "source": [
    "## AutoRAG 팀에서의 PDF 실험\n",
    "\n",
    "AutoRAG 에서 진행한 실험을 토대로 작성한 순위표\n",
    "\n",
    "아래 표기된 숫자는 등수를 나타냅니다. (The lower, the better)\n",
    "\n",
    "| | PDFMiner | PDFPlumber | PyPDFium2 | PyMuPDF | PyPDF2 |\n",
    "|----------|:---------:|:----------:|:---------:|:-------:|:-----:|\n",
    "| Medical  | 1         | 2          | 3         | 4       | 5     |\n",
    "| Law      | 3         | 1          | 1         | 3       | 5     |\n",
    "| Finance  | 1         | 2          | 2         | 4       | 5     |\n",
    "| Public   | 1         | 1          | 1         | 4       | 5     |\n",
    "| Sum      | 5         | 5          | 7         | 15      | 20    |\n",
    "\n",
    "출처: [AutoRAG Medium 블로그](https://velog.io/@autorag/PDF-%ED%95%9C%EA%B8%80-%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%B6%94%EC%B6%9C-%EC%8B%A4%ED%97%98#%EC%B4%9D%ED%8F%89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1907c14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f023d22",
   "metadata": {},
   "source": [
    "## 실습에 활용한 문서\n",
    "\n",
    "소프트웨어정책연구소(SPRi) - 2023년 12월호\n",
    "\n",
    "- 저자: 유재흥(AI정책연구실 책임연구원), 이지수(AI정책연구실 위촉연구원)\n",
    "- 링크: https://spri.kr/posts/view/23669\n",
    "- 파일명: `SPRI_AI_Brief_2023년12월호_F.pdf`\n",
    "\n",
    "**참고**: 위의 파일은 `data` 폴더 내에 다운로드 받으세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5180451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일 로드\n",
    "# FILE_PATH = \"./data/SPRI_AI_Brief_2023년12월호_F.pdf\"\n",
    "FILE_PATH = \"./data/2103_page5.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a1978423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metadata(docs):\n",
    "    if docs:\n",
    "        print(\"[metadata]\")\n",
    "        print(list(docs[0].metadata.keys()))\n",
    "        print(\"\\n[examples]\")\n",
    "        max_key_length = max(len(k) for k in docs[0].metadata.keys())\n",
    "        for k, v in docs[0].metadata.items():\n",
    "            print(f\"{k:<{max_key_length}} : {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c404e7d",
   "metadata": {},
   "source": [
    "## PyPDF\n",
    "\n",
    "여기에서는 `pypdf`를 사용하여 PDF를 문서 배열로 로드하며, 각 문서는 `page` 번호와 함께 페이지 내용 및 메타데이터를 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9673857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa20caf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 파일 경로 설정\n",
    "loader = PyPDFLoader(FILE_PATH)\n",
    "\n",
    "# PDF 로더 초기화\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "# print(docs[10].page_content[:300])  # 10페이지의 300자 내용 출력\n",
    "print(docs[0].page_content[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ba1532d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Adobe Acrobat (64-bit) 25 Paper Capture Plug-in', 'creator': 'PyPDF', 'creationdate': '2025-08-22T12:38:36+09:00', 'author': 'Heejin Park', 'moddate': '2025-08-22T12:47:11+09:00', 'title': 'C:\\\\Users\\\\park0\\\\Downloads\\\\2103.15348v2.pdf', 'source': './data/2103_page1.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='LayoutParser: A Unified Toolkit for Deep \\nLearning Based Documen t Image Analysis \\nIZOZ \\nunr \\nIt Zejiang Shen1 詞),Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain \\nLee4, Jacob Carlson3, and Weining Li5 \\n1 Allen Institute for AI \\nshannons©allena i.org \\n2 Brown University \\nruochen_zhan g©brown.edu \\n3 Harvard University \\n{melissadell, jacob_carlson}© fas.harvard.edu \\n4 University of Washington \\nbcgl©cs.wash ington.edu \\n5 University of Waterloo \\nw422 li©u멀aterloo.ca \\n[AU\\n·s~] \\n현\\n/oo\\n寸\\nESI•EOINA!X1B Abstract . Recent advances in document image analysis (DIA) have been \\nprimarily driven by the application of neural networks. Ideally, research \\noutcomes could be easily deployed in production and extended for further \\ninvestigation. However, various factors like loosely organized codebases \\nand sophisticated model configurations complicate the easy reuse of im\\xad\\nportant innovations by a wide audience. Though there have been on-going \\nefforts to improve reusability and simplify deep learning (DL) model \\ndevelopment in disciplines like natural language processing and computer \\nvision, none of them are optimized for challenges in the domain of DIA. \\nThis represents a major gap in the existing toolkit, as DIA is central to \\nacademic research across a wide range of disciplines in the social sciences \\nand humanities. This paper introduces LayoutParser, an open-source \\nlibrary for streamlining the usage of DL in DIA research and applica\\xad\\ntions. The core LayoutParser library comes with a set of simple and \\nintuitive interfaces for applying and customizing DL models for layout de\\xad\\ntection, character recognition, and many other document processing tasks. \\nTo promote extensibility, LayoutParser also incorporates a community \\nplatform for sharing both pre-trained models and full documen t digiti\\xad\\nzation pipelines. We demonstrate that LayoutParser is helpful for both \\nlightweight and large-scale digitization pipelines in real-word use cases. \\nThe library is publicly available at https : //layout-parser . github . io. \\nKeywords: Documen t Image Analysis • Deep Learning • Layout Analysis \\n• Character Recognition • Open Source library • Toolkit. \\n1 Introduction \\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of \\ndocumen t image analysis (DIA) tasks including documen t image classification [ 11,')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f4dea",
   "metadata": {},
   "source": [
    "[Document(metadata={'producer': 'Adobe Acrobat (64-bit) 25 Paper Capture Plug-in', 'creator': 'PyPDF', 'creationdate': '2025-08-22T12:38:36+09:00', 'author': 'Heejin Park', 'moddate': '2025-08-22T12:47:11+09:00', 'title': 'C:\\\\Users\\\\park0\\\\Downloads\\\\2103.15348v2.pdf', 'source': './data/2103_page1.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='LayoutParser: A Unified Toolkit for Deep \\nLearning Based Documen t Image Analysis \\nIZOZ \\nunr \\nIt Zejiang Shen1 詞),Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain \\nLee4, Jacob Carlson3, and Weining Li5 \\n1 Allen Institute for AI \\nshannons©allena i.org \\n2 Brown University \\nruochen_zhan g©brown.edu \\n3 Harvard University \\n{melissadell, jacob_carlson}© fas.harvard.edu \\n4 University of Washington \\nbcgl©cs.wash ington.edu \\n5 University of Waterloo \\nw422 li©u멀aterloo.ca \\n[AU\\n·s~] \\n현\\n/oo\\n寸\\nESI•EOINA!X1B Abstract . Recent advances in document image analysis (DIA) have been \\nprimarily driven by the application of neural networks. Ideally, research \\noutcomes could be easily deployed in production and extended for further \\ninvestigation. However, various factors like loosely organized codebases \\nand sophisticated model configurations complicate the easy reuse of im\\xad\\nportant innovations by a wide audience. Though there have been on-going \\nefforts to improve reusability and simplify deep learning (DL) model \\ndevelopment in disciplines like natural language processing and computer \\nvision, none of them are optimized for challenges in the domain of DIA. \\nThis represents a major gap in the existing toolkit, as DIA is central to \\nacademic research across a wide range of disciplines in the social sciences \\nand humanities. This paper introduces LayoutParser, an open-source \\nlibrary for streamlining the usage of DL in DIA research and applica\\xad\\ntions. The core LayoutParser library comes with a set of simple and \\nintuitive interfaces for applying and customizing DL models for layout de\\xad\\ntection, character recognition, and many other document processing tasks. \\nTo promote extensibility, LayoutParser also incorporates a community \\nplatform for sharing both pre-trained models and full documen t digiti\\xad\\nzation pipelines. We demonstrate that LayoutParser is helpful for both \\nlightweight and large-scale digitization pipelines in real-word use cases. \\nThe library is publicly available at https : //layout-parser . github . io. \\nKeywords: Documen t Image Analysis • Deep Learning • Layout Analysis \\n• Character Recognition • Open Source library • Toolkit. \\n1 Introduction \\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of \\ndocumen t image analysis (DIA) tasks including documen t image classification [ 11,')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "453f2103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'author', 'moddate', 'title', 'source', 'total_pages', 'page', 'page_label']\n",
      "\n",
      "[examples]\n",
      "producer     : Adobe Acrobat (64-bit) 25 Paper Capture Plug-in\n",
      "creator      : PyPDF\n",
      "creationdate : 2025-08-22T12:38:36+09:00\n",
      "author       : Heejin Park\n",
      "moddate      : 2025-08-22T12:47:11+09:00\n",
      "title        : C:\\Users\\park0\\Downloads\\2103.15348v2.pdf\n",
      "source       : ./data/2103_page1.pdf\n",
      "total_pages  : 1\n",
      "page         : 0\n",
      "page_label   : 1\n"
     ]
    }
   ],
   "source": [
    "# 메타데이터 출력\n",
    "show_metadata(docs)\n",
    "\n",
    "# langchain의 버전에 따라서 메타데이터 출력 형식이 다를 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96845496",
   "metadata": {},
   "source": [
    "### PyPDF(OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e3c86",
   "metadata": {},
   "source": [
    "일부 PDF에는 스캔된 문서나 그림 내에 텍스트 이미지가 포함되어 있습니다. `rapidocr-onnxruntime` 패키지를 사용하여 이미지에서 텍스트를 추출할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "009b9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU rapidocr-onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02c1614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일 로드\n",
    "# FILE_PATH = \"./data/SPRI_AI_Brief_2023년12월호_F.pdf\"\n",
    "FILE_PATH = \"./data/2103_page4.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b5334000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# PDF 로더 초기화, 이미지 추출 옵션 활성화\n",
    "loader = PyPDFLoader(FILE_PATH, extract_images=True)\n",
    "\n",
    "# PDF 페이지 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 페이지 내용 접근\n",
    "# print(docs[4].page_content[:300])\n",
    "print(docs[0].page_content[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "335fbfb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Adobe Acrobat (64-bit) 25 Paper Capture Plug-in', 'creator': 'PyPDF', 'creationdate': '2025-08-22T12:39:29+09:00', 'author': 'Heejin Park', 'moddate': '2025-08-22T12:47:30+09:00', 'title': 'C:\\\\Users\\\\park0\\\\Downloads\\\\2103.15348v2.pdf', 'source': './data/2103_page5.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}, page_content='LayoutParser: A Unified Toolkit for DL-Based DIA 5 \\nTable 1: Current layout detection models in the LayoutParser model zoo \\nDataset I Base Model11 Large Model I Notes \\nPubLayNet [38] I F / M I M I Layouts of modern scientific documents \\nPRimA [3] I M I - I Layouts of scanned modern magazines and scientific reports \\nNewspaper [17] I F I - I Layouts of scanned US newspapers from the 20th century \\nTableBank [18] I F I F I Table region on modern scientific and business documen t \\nHJDataset [31] I F / M I - I Layouts of history Japanese documen ts \\n1 For each dataset , we train several models of different sizes for different needs (the trade-off between accuracy \\nvs. computational cost). For \"base model\" and \"large model\" , we refer to using the ResNet 50 or ResNet 101 \\nbackbones [13] , respectively. One can train models of different architectures, like Faster R-CNN [28] (F) and Mask \\nR-CNN [12] (M). For example, an F in the Large Model column indicates it has a Faster R-CNN model trained \\nusing the ResNet 101 backbone. The platform is maintained and a number of additions will be made to the model \\nzoo in coming months. \\nlayout data structures, which are optimized for efficiency and versatility. 3) When \\nnecessary, users can employ existing or customized OCR models via the unified \\nAPI provided in the OCR module. 4) LayoutParser comes with a set of utility \\nfunctions for the visualization and storage of the layout data. 5) LayoutParser \\nis also highly customizable, via its integration with functions for layout data \\nannotation and model training. We now provide detailed descriptions for each \\ncomponent. \\n3.1 Layout Detection Models \\nIn LayoutParser, a layout model takes a documen t image as an input and \\ngenerates a list of rectangular boxes for the target content regions. Different \\nfrom traditional methods, it relies on deep convolutional neural networks rather \\nthan manually curated rules to identify content regions. It is formulated as an \\nobject detection problem and state-of-the-art models like Faster R-CNN [28] and \\nMask R-CNN [12] are used. This yields prediction results of high accuracy and \\nmakes it possible to build a concise, generalized interface for layout detection. \\nLayoutParser, built upon Detectron2 [35] , provides a minimal API that can \\nperform layout detection with only four lines of code in Python: \\n1 import layoutparser as lp \\n2 image = cv2.imread( \"image_file\") # load images \\na model = lp . Detectron2LayoutModel ( \\n4 \"lp://PubLa yNet/faster_rcnn_R_50_FPN_3x/con fig\") \\ns layout = model.de tect(image) \\nLayoutParser provides a wealth of pre-trained model weights using various \\ndatasets covering different languages, time periods, and document types. Due to \\ndomain shift [7] , the prediction performance can notably drop when models are ap\\xad\\nplied to target samples that are significantly different from the training dataset. As \\ndocument structures and layouts vary greatly in different domains, it is important \\nto select models trained on a dataset similar to the test samples. A semantic syntax \\nis used for initializing the model weights in LayoutParser, using both the dataset \\nname and model name lp : //<dataset-name>/<model-arch itecture-name>.')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fe6caa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'author', 'keywords', 'moddate', 'ptex.fullbanner', 'subject', 'title', 'trapped', 'source', 'total_pages', 'page', 'page_label']\n",
      "\n",
      "[examples]\n",
      "producer        : pdfTeX-1.40.21\n",
      "creator         : LaTeX with hyperref\n",
      "creationdate    : 2021-06-22T01:27:10+00:00\n",
      "author          : \n",
      "keywords        : \n",
      "moddate         : 2021-06-22T01:27:10+00:00\n",
      "ptex.fullbanner : This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2\n",
      "subject         : \n",
      "title           : \n",
      "trapped         : /False\n",
      "source          : https://arxiv.org/pdf/2103.15348.pdf\n",
      "total_pages     : 16\n",
      "page            : 0\n",
      "page_label      : 1\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)\n",
    "\n",
    "# langchain의 버전에 따라서 메타데이터 출력 형식이 다를 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a191d5c",
   "metadata": {},
   "source": [
    "## PyMuPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88bca1",
   "metadata": {},
   "source": [
    "**PyMuPDF** 는 속도 최적화가 되어 있으며, PDF 및 해당 페이지에 대한 자세한 메타데이터를 포함하고 있습니다. 페이지 당 하나의 문서를 반환합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac56d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47e7a947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  \n",
      "2023-12월호\n",
      "8\n",
      "코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\n",
      "n 코히어와 12개 기관이  광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, \n",
      "작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시\n",
      "n 대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 \n",
      "구성과 계보도 추적 가능\n",
      "KEY Contents\n",
      "£ 데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\n",
      "n AI 기업 코히어\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# PyMuPDF 로더 인스턴스 생성\n",
    "loader = PyMuPDFLoader(FILE_PATH)\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[10].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbca8760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'source', 'file_path', 'total_pages', 'format', 'title', 'author', 'subject', 'keywords', 'moddate', 'trapped', 'modDate', 'creationDate', 'page']\n",
      "\n",
      "[examples]\n",
      "producer     : Hancom PDF 1.3.0.542\n",
      "creator      : Hwp 2018 10.0.0.13462\n",
      "creationdate : 2023-12-08T13:28:38+09:00\n",
      "source       : ./data/SPRI_AI_Brief_2023년12월호_F.pdf\n",
      "file_path    : ./data/SPRI_AI_Brief_2023년12월호_F.pdf\n",
      "total_pages  : 23\n",
      "format       : PDF 1.4\n",
      "title        : \n",
      "author       : dj\n",
      "subject      : \n",
      "keywords     : \n",
      "moddate      : 2023-12-08T13:28:38+09:00\n",
      "trapped      : \n",
      "modDate      : D:20231208132838+09'00'\n",
      "creationDate : D:20231208132838+09'00'\n",
      "page         : 0\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89745c9",
   "metadata": {},
   "source": [
    "## Unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72199f11",
   "metadata": {},
   "source": [
    "[Unstructured](https://unstructured-io.github.io/unstructured/)는 Markdown이나 PDF와 같은 비구조화된 또는 반구조화된 파일 형식을 다루기 위한 공통 인터페이스를 지원합니다. \n",
    "\n",
    "LangChain의 [UnstructuredPDFLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.UnstructuredPDFLoader.html)는 Unstructured와 통합되어 PDF 문서를 LangChain [Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html) 객체로 파싱합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6cc687b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU unstructured\n",
    "FILE_PATH = \"./data/SPRI_AI_Brief_2023년12월호_F.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40cb362e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfminer.psexceptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m loader = UnstructuredPDFLoader(FILE_PATH)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 데이터 로드\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m docs = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 문서의 내용 출력\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(docs[\u001b[32m0\u001b[39m].page_content[:\u001b[32m300\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:32\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.lazy_load())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\langchain_community\\document_loaders\\unstructured.py:107\u001b[39m, in \u001b[36mUnstructuredBaseLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Document]:\n\u001b[32m    106\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     elements = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mself\u001b[39m._post_process_elements(elements)\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33melements\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\langchain_community\\document_loaders\\pdf.py:92\u001b[39m, in \u001b[36mUnstructuredPDFLoader._get_elements\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_elements\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partition_pdf\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m partition_pdf(filename=\u001b[38;5;28mself\u001b[39m.file_path, **\u001b[38;5;28mself\u001b[39m.unstructured_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\unstructured\\partition\\pdf.py:70\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mform_extraction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_form_extraction\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     66\u001b[39m     check_element_types_to_extract,\n\u001b[32m     67\u001b[39m     convert_pdf_to_images,\n\u001b[32m     68\u001b[39m     save_elements,\n\u001b[32m     69\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfminer_processing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     71\u001b[39m     check_annotations_within_element,\n\u001b[32m     72\u001b[39m     clean_pdfminer_inner_elements,\n\u001b[32m     73\u001b[39m     get_links_in_element,\n\u001b[32m     74\u001b[39m     get_uris,\n\u001b[32m     75\u001b[39m     get_words_from_obj,\n\u001b[32m     76\u001b[39m     map_bbox_and_index,\n\u001b[32m     77\u001b[39m     merge_inferred_with_extracted_layout,\n\u001b[32m     78\u001b[39m )\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfminer_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     80\u001b[39m     PDFMinerConfig,\n\u001b[32m     81\u001b[39m     open_pdfminer_pages_generator,\n\u001b[32m     82\u001b[39m     rect_to_bbox,\n\u001b[32m     83\u001b[39m )\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstrategies\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m determine_pdf_or_image_strategy, validate_strategy\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\unstructured\\partition\\pdf_image\\pdfminer_processing.py:17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocuments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01melements\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CoordinatesMetadata, ElementType\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m remove_control_characters\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdf_image\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfminer_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     18\u001b[39m     PDFMinerConfig,\n\u001b[32m     19\u001b[39m     extract_image_objects,\n\u001b[32m     20\u001b[39m     extract_text_objects,\n\u001b[32m     21\u001b[39m     open_pdfminer_pages_generator,\n\u001b[32m     22\u001b[39m     rect_to_bbox,\n\u001b[32m     23\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m env_config\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartition\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SORT_MODE_BASIC, Source\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\unstructured\\partition\\pdf_image\\pdfminer_utils.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfinterp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFPageInterpreter, PDFResourceManager\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpdfpage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PDFPage\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpdfminer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpsexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PSSyntaxError\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munstructured\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logger\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pdfminer.psexceptions'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "# UnstructuredPDFLoader 인스턴스 생성\n",
    "loader = UnstructuredPDFLoader(FILE_PATH)\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b929e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3115d62b",
   "metadata": {},
   "source": [
    "내부적으로 비정형에서는 텍스트 청크마다 서로 다른 \"**요소**\"를 만듭니다. 기본적으로 이들은 결합되어 있지만 `mode=\"elements\"`를 지정하여 쉽게 분리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f97007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UnstructuredPDFLoader 인스턴스 생성(mode=\"elements\")\n",
    "loader = UnstructuredPDFLoader(FILE_PATH, mode=\"elements\")\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ab703e",
   "metadata": {},
   "source": [
    "이 특정 문서에 대한 전체 요소 유형 집합을 참조하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd7976",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(doc.metadata[\"category\"] for doc in docs)  # 데이터 카테고리 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec0c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5097872",
   "metadata": {},
   "source": [
    "## PyPDFium2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18c84bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief | \n",
      "2023-12월호\n",
      "8\n",
      "코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개\n",
      "n 코히어와 12개 기관이 광범위한 데이터셋에 대한 감사를 통해 원본 데이터 출처, 재라이선스 상태, 작성자 등 다양한 정보를 제공하는 ‘데이터 출처 탐색기’ 플랫폼을 출시\n",
      "n 대화형 플랫폼을 통해 개발자는 데이터셋의 라이선스 상태를 쉽게 파악할 수 있으며 데이터셋의 \n",
      "구성과 계보도 추적 가능\n",
      "KEY Contents\n",
      "£ 데이터 출처 탐색기, 광범위한 데이터셋 정보 제공을 통해 데이터 투명성 향상\n",
      "n AI 기업 코히어(Co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\pypdfium2\\_helpers\\textpage.py:80: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n",
      "  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "\n",
    "# PyPDFium2 로더 인스턴스 생성\n",
    "loader = PyPDFium2Loader(FILE_PATH)\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[10].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4cd8966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'title', 'author', 'subject', 'keywords', 'moddate', 'source', 'total_pages', 'page']\n",
      "\n",
      "[examples]\n",
      "producer     : Hancom PDF 1.3.0.542\n",
      "creator      : Hwp 2018 10.0.0.13462\n",
      "creationdate : 2023-12-08T13:28:38+09:00\n",
      "title        : \n",
      "author       : dj\n",
      "subject      : \n",
      "keywords     : \n",
      "moddate      : 2023-12-08T13:28:38+09:00\n",
      "source       : ./data/SPRI_AI_Brief_2023년12월호_F.pdf\n",
      "total_pages  : 23\n",
      "page         : 0\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b2a6a",
   "metadata": {},
   "source": [
    "## PDFMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feac159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023년  12월호\n",
      "\f2023년  12월호\n",
      "\n",
      "Ⅰ.  인공지능  산업  동향  브리프\n",
      "\n",
      "  1.  정책/법제 \n",
      "\n",
      "      ▹  미국,  안전하고  신뢰할  수  있는  AI  개발과  사용에  관한  행정명령  발표    ························· 1\n",
      "\n",
      "      ▹  G7,  히로시마  AI  프로세스를  통해  AI  기업  대상  국제  행동강령에  합의 ··························· 2\n",
      "\n",
      "      ▹  영국  AI  안전성  정상회의에  참가한  28개국,  AI  위험에  공동  \n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "\n",
    "# PDFMiner 로더 인스턴스 생성\n",
    "loader = PDFMinerLoader(FILE_PATH)\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])\n",
    "\n",
    "# 한글 문서의 경우 띄어쓰기가 2칸씩 될 수 있으므로 주의가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65a85f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'author', 'moddate', 'pdfversion', 'total_pages', 'source']\n",
      "\n",
      "[examples]\n",
      "producer     : Hancom PDF 1.3.0.542\n",
      "creator      : Hwp 2018 10.0.0.13462\n",
      "creationdate : 2023-12-08T13:28:38+09:00\n",
      "author       : dj\n",
      "moddate      : 2023-12-08T13:28:38+09:00\n",
      "pdfversion   : 1.4\n",
      "total_pages  : 23\n",
      "source       : ./data/SPRI_AI_Brief_2023년12월호_F.pdf\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d918ef7",
   "metadata": {},
   "source": [
    "**PDFMiner**를 사용하여 HTML 텍스트 생성\n",
    "\n",
    "이 방법은 출력된 HTML 콘텐츠를 `BeautifulSoup`을 통해 파싱함으로써 글꼴 크기, 페이지 번호, PDF 헤더/푸터 등에 대한 보다 구조화되고 풍부한 정보를 얻을 수 있게 하여 텍스트를 의미론적으로 섹션으로 분할하는 데 도움이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFMinerPDFasHTMLLoader\n",
    "\n",
    "# PDFMinerPDFasHTMLLoader 인스턴스 생성\n",
    "loader = PDFMinerPDFasHTMLLoader(FILE_PATH)\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aacfd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df728c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(docs[0].page_content, \"html.parser\")  # HTML 파서 초기화\n",
    "content = soup.find_all(\"div\")  # 모든 div 태그 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d75111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cur_fs = None\n",
    "cur_text = \"\"\n",
    "snippets = []  # 동일한 글꼴 크기의 모든 스니펫 수집\n",
    "for c in content:\n",
    "    sp = c.find(\"span\")\n",
    "    if not sp:\n",
    "        continue\n",
    "    st = sp.get(\"style\")\n",
    "    if not st:\n",
    "        continue\n",
    "    fs = re.findall(\"font-size:(\\d+)px\", st)\n",
    "    if not fs:\n",
    "        continue\n",
    "    fs = int(fs[0])\n",
    "    if not cur_fs:\n",
    "        cur_fs = fs\n",
    "    if fs == cur_fs:\n",
    "        cur_text += c.text\n",
    "    else:\n",
    "        snippets.append((cur_text, cur_fs))\n",
    "        cur_fs = fs\n",
    "        cur_text = c.text\n",
    "snippets.append((cur_text, cur_fs))\n",
    "# 중복 스니펫 제거 전략 추가 가능성 (PDF의 헤더/푸터가 여러 페이지에 걸쳐 나타나므로 중복 발견 시 중복 정보로 간주 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8061d2e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snippets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m semantic_snippets = []\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 제목 가정: 높은 글꼴 크기\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[43msnippets\u001b[49m:\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# 새 제목 판별: 현재 스니펫 글꼴 > 이전 제목 글꼴\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m      9\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m semantic_snippets\n\u001b[32m     10\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m s[\u001b[32m1\u001b[39m] > semantic_snippets[cur_idx].metadata[\u001b[33m\"\u001b[39m\u001b[33mheading_font\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     11\u001b[39m     ):\n\u001b[32m     12\u001b[39m         metadata = {\u001b[33m\"\u001b[39m\u001b[33mheading\u001b[39m\u001b[33m\"\u001b[39m: s[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mcontent_font\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mheading_font\u001b[39m\u001b[33m\"\u001b[39m: s[\u001b[32m1\u001b[39m]}\n",
      "\u001b[31mNameError\u001b[39m: name 'snippets' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "cur_idx = -1\n",
    "semantic_snippets = []\n",
    "# 제목 가정: 높은 글꼴 크기\n",
    "for s in snippets:\n",
    "    # 새 제목 판별: 현재 스니펫 글꼴 > 이전 제목 글꼴\n",
    "    if (\n",
    "        not semantic_snippets\n",
    "        or s[1] > semantic_snippets[cur_idx].metadata[\"heading_font\"]\n",
    "    ):\n",
    "        metadata = {\"heading\": s[0], \"content_font\": 0, \"heading_font\": s[1]}\n",
    "        metadata.update(docs[0].metadata)\n",
    "        semantic_snippets.append(Document(page_content=\"\", metadata=metadata))\n",
    "        cur_idx += 1\n",
    "        continue\n",
    "\n",
    "    # 동일 섹션 내용 판별: 현재 스니펫 글꼴 <= 이전 내용 글꼴\n",
    "    if (\n",
    "        not semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
    "        or s[1] <= semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
    "    ):\n",
    "        semantic_snippets[cur_idx].page_content += s[0]\n",
    "        semantic_snippets[cur_idx].metadata[\"content_font\"] = max(\n",
    "            s[1], semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # 새 섹션 생성 조건: 현재 스니펫 글꼴 > 이전 내용 글꼴, 이전 제목 글꼴 미만\n",
    "    metadata = {\"heading\": s[0], \"content_font\": 0, \"heading_font\": s[1]}\n",
    "    metadata.update(docs[0].metadata)\n",
    "    semantic_snippets.append(Document(page_content=\"\", metadata=metadata))\n",
    "    cur_idx += 1\n",
    "\n",
    "print(semantic_snippets[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0740f50",
   "metadata": {},
   "source": [
    "## PyPDF 디렉토리\n",
    "\n",
    "디렉토리에서 PDF를 로드하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbbbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# 디렉토리 경로\n",
    "loader = PyPDFDirectoryLoader(\"data/\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 개수 출력\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ffd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문서의 내용 출력\n",
    "print(docs[50].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c68b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata 출력\n",
    "print(docs[50].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb92d77",
   "metadata": {},
   "source": [
    "## PDFPlumber\n",
    "\n",
    "PyMuPDF와 마찬가지로, 출력 문서는 PDF와 그 페이지에 대한 자세한 메타데이터를 포함하며, 페이지 당 하나의 문서를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97bd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "# PDF 문서 로더 인스턴스 생성\n",
    "loader = PDFPlumberLoader(FILE_PATH)\n",
    "\n",
    "# 문서 로딩\n",
    "docs = loader.load()\n",
    "\n",
    "# 첫 번째 문서 데이터 접근\n",
    "print(docs[10].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c637a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-Us6BDj1P-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
