{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c66f34be",
   "metadata": {},
   "source": [
    "# PDF\n",
    "\n",
    "[Portable Document Format (PDF)](https://en.wikipedia.org/wiki/PDF), ISO 32000으로 표준화된 파일 형식은 Adobe가 1992년에 문서를 제시하기 위해 개발했으며, 이는 응용 소프트웨어, 하드웨어 및 운영 시스템에 독립적인 방식으로 텍스트 서식 및 이미지를 포함합니다.\n",
    "\n",
    "이 가이드는 `PDF` 문서를 LangChain [Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) 형식으로 로드하는 방법을 다룹니다. 이 형식은 다운스트림에서 사용됩니다.\n",
    "\n",
    "LangChain은 다양한 PDF 파서와 통합됩니다. 일부는 간단하고 상대적으로 저수준이며, 다른 일부는 OCR 및 이미지 처리를 지원하거나 고급 문서 레이아웃 분석을 수행합니다. \n",
    "\n",
    "올바른 선택은 사용자의 애플리케이션에 따라 달라집니다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- [LangChain 도큐먼트](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/pdf/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3883eda",
   "metadata": {},
   "source": [
    "## AutoRAG 팀에서의 PDF 실험\n",
    "\n",
    "AutoRAG 에서 진행한 실험을 토대로 작성한 순위표\n",
    "\n",
    "아래 표기된 숫자는 등수를 나타냅니다. (The lower, the better)\n",
    "\n",
    "| | PDFMiner | PDFPlumber | PyPDFium2 | PyMuPDF | PyPDF2 |\n",
    "|----------|:---------:|:----------:|:---------:|:-------:|:-----:|\n",
    "| Medical  | 1         | 2          | 3         | 4       | 5     |\n",
    "| Law      | 3         | 1          | 1         | 3       | 5     |\n",
    "| Finance  | 1         | 2          | 2         | 4       | 5     |\n",
    "| Public   | 1         | 1          | 1         | 4       | 5     |\n",
    "| Sum      | 5         | 5          | 7         | 15      | 20    |\n",
    "\n",
    "출처: [AutoRAG Medium 블로그](https://velog.io/@autorag/PDF-%ED%95%9C%EA%B8%80-%ED%85%8D%EC%8A%A4%ED%8A%B8-%EC%B6%94%EC%B6%9C-%EC%8B%A4%ED%97%98#%EC%B4%9D%ED%8F%89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1907c14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f023d22",
   "metadata": {},
   "source": [
    "## 실습에 활용한 문서\n",
    "\n",
    "소프트웨어정책연구소(SPRi) - 2023년 12월호\n",
    "\n",
    "- 저자: 유재흥(AI정책연구실 책임연구원), 이지수(AI정책연구실 위촉연구원)\n",
    "- 링크: https://spri.kr/posts/view/23669\n",
    "- 파일명: `SPRI_AI_Brief_2023년12월호_F.pdf`\n",
    "\n",
    "**참고**: 위의 파일은 `data` 폴더 내에 다운로드 받으세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5180451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일 로드\n",
    "# FILE_PATH = \"./data/SPRI_AI_Brief_2023년12월호_F.pdf\"\n",
    "FILE_PATH = \"./data/2103_page1.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1978423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metadata(docs):\n",
    "    if docs:\n",
    "        print(\"[metadata]\")\n",
    "        print(list(docs[0].metadata.keys()))\n",
    "        print(\"\\n[examples]\")\n",
    "        max_key_length = max(len(k) for k in docs[0].metadata.keys())\n",
    "        for k, v in docs[0].metadata.items():\n",
    "            print(f\"{k:<{max_key_length}} : {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c404e7d",
   "metadata": {},
   "source": [
    "## PyPDF\n",
    "\n",
    "여기에서는 `pypdf`를 사용하여 PDF를 문서 배열로 로드하며, 각 문서는 `page` 번호와 함께 페이지 내용 및 메타데이터를 포함합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9673857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06e5a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일 로드\n",
    "# FILE_PATH = \"./data/SPRI_AI_Brief_2023년12월호_F.pdf\"\n",
    "FILE_PATH = \"./data/2103_page1.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa20caf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutParser: A Unified Toolkit for Deep \n",
      "Learning Based Documen t Image Analysis \n",
      "IZOZ \n",
      "unr \n",
      "It Zejiang Shen1 詞),Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain \n",
      "Lee4, Jacob Carlson3, and Weining Li5 \n",
      "1 Allen Institute for AI \n",
      "shannons©allena i.org \n",
      "2 Brown University \n",
      "ruochen_zhan g©brown.edu \n",
      "3 Harvard University \n",
      "{melissadell, jacob_carlson}© fas.harvard.edu \n",
      "4 University of Washington \n",
      "bcgl©cs.wash ington.edu \n",
      "5 University of Waterloo \n",
      "w422 li©u멀aterloo.ca \n",
      "[AU\n",
      "·s~] \n",
      "현\n",
      "/oo\n",
      "寸\n",
      "ESI•EOINA!X1B Abstract . Recent advances in document image analysis (DIA) have been \n",
      "primarily driven by the application of neural networks. Ideally, research \n",
      "outcomes could be easily deployed in production and extended for further \n",
      "investigation. However, various factors like loosely organized codebases \n",
      "and sophisticated model configurations complicate the easy reuse of im­\n",
      "portant innovations by a wide audience. Though there have been on-going \n",
      "efforts to improve reusability and simplify deep learning (DL) model \n",
      "development in disciplines like natural language processing and computer \n",
      "vision, none of them are optimized for challenges in the domain of DIA. \n",
      "This represents a major gap in the existing toolkit, as DIA is central to \n",
      "academic research across a wide range of disciplines in the social sciences \n",
      "and humanities. This paper introduces LayoutParser, an open-source \n",
      "library for streamlining the usage of DL in DIA research and applica­\n",
      "tions. The core LayoutParser library comes with a set of simple and \n",
      "intuitive interfaces for applying and customizing DL models for layout de­\n",
      "tection, character recognition, and many other document processing tasks. \n",
      "To promote extensibility, LayoutParser also incorporates a community \n",
      "platform for sharing both pre-trained models and full documen t digiti­\n",
      "zation pipelines. We demonstrate that LayoutParser is helpful for both \n",
      "lightweight and large-scale digitization pipelines in real-word use cases. \n",
      "The library is publicly available at https : //layout-parser . github . io. \n",
      "Keywords: Documen t Image Analysis • Deep Learning • Layout Analysis \n",
      "• Character Recognition • Open Source library • Toolkit. \n",
      "1 Introduction \n",
      "Deep Learning(DL)-based approaches are the state-of-the-art for a wide range of \n",
      "documen t image analysis (DIA) tasks including documen t image classification [ 11,\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 파일 경로 설정\n",
    "loader = PyPDFLoader(FILE_PATH)\n",
    "\n",
    "# PDF 로더 초기화\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "# print(docs[10].page_content[:300])  # 10페이지의 300자 내용 출력\n",
    "print(docs[0].page_content[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "453f2103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'author', 'moddate', 'title', 'source', 'total_pages', 'page', 'page_label']\n",
      "\n",
      "[examples]\n",
      "producer     : Adobe Acrobat (64-bit) 25 Paper Capture Plug-in\n",
      "creator      : PyPDF\n",
      "creationdate : 2025-08-22T12:38:36+09:00\n",
      "author       : Heejin Park\n",
      "moddate      : 2025-08-22T12:47:11+09:00\n",
      "title        : C:\\Users\\park0\\Downloads\\2103.15348v2.pdf\n",
      "source       : ./data/2103_page1.pdf\n",
      "total_pages  : 1\n",
      "page         : 0\n",
      "page_label   : 1\n"
     ]
    }
   ],
   "source": [
    "# 메타데이터 출력\n",
    "show_metadata(docs)\n",
    "\n",
    "# langchain의 버전에 따라서 메타데이터 출력 형식이 다를 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96845496",
   "metadata": {},
   "source": [
    "### PyPDF(OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e3c86",
   "metadata": {},
   "source": [
    "일부 PDF에는 스캔된 문서나 그림 내에 텍스트 이미지가 포함되어 있습니다. `rapidocr-onnxruntime` 패키지를 사용하여 이미지에서 텍스트를 추출할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "009b9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU rapidocr-onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02c1614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일 로드\n",
    "# FILE_PATH = \"./data/SPRI_AI_Brief_2023년12월호_F.pdf\"\n",
    "FILE_PATH = \"./data/2103_page1.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b5334000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayoutParser: A Unified Toolkit for Deep \n",
      "Learning Based Documen t Image Analysis \n",
      "IZOZ \n",
      "unr \n",
      "It Zejiang Shen1 詞),Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain \n",
      "Lee4, Jacob Carlson3, and Weining Li5 \n",
      "1 Allen Institute for AI \n",
      "shannons©allena i.org \n",
      "2 Brown University \n",
      "ruochen_zhan g©brown.edu \n",
      "3 Harvard University \n",
      "{melissadell, jacob_carlson}© fas.harvard.edu \n",
      "4 University of Washington \n",
      "bcgl©cs.wash ington.edu \n",
      "5 University of Waterloo \n",
      "w422 li©u멀aterloo.ca \n",
      "[AU\n",
      "·s~] \n",
      "현\n",
      "/oo\n",
      "寸\n",
      "ESI•EOINA!X1B Abstract . Recent advances in document image analysis (DIA) have been \n",
      "primarily driven by the application of neural networks. Ideally, research \n",
      "outcomes could be easily deployed in production and extended for further \n",
      "investigation. However, various factors like loosely organized codebases \n",
      "and sophisticated model configurations complicate the easy reuse of im­\n",
      "portant innovations by a wide audience. Though there have been on-going \n",
      "efforts to improve reusability and simplify deep learning (DL) model \n",
      "development in disciplines like natural language processing and computer \n",
      "vision, none of them are optimized for challenges in the domain of DIA. \n",
      "This represents a major gap in the existing toolkit, as DIA is central to \n",
      "academic research across a wide range of disciplines in the social sciences \n",
      "and humanities. This paper introduces LayoutParser, an open-source \n",
      "library for streamlining the usage of DL in DIA research and applica­\n",
      "tions. The core LayoutParser library comes with a set of simple and \n",
      "intuitive interfaces for applying and customizing DL models for layout de­\n",
      "tection, character recognition, and many other document processing tasks. \n",
      "To promote extensibility, LayoutParser also incorporates a community \n",
      "platform for sharing both pre-trained models and full documen t digiti­\n",
      "zation pipelines. We demonstrate that LayoutParser is helpful for both \n",
      "lightweight and large-scale digitization pipelines in real-word use cases. \n",
      "The library is publicly available at https : //layout-parser . github . io. \n",
      "Keywords: Documen t Image Analysis • Deep Learning • Layout Analysis \n",
      "• Character Recognition • Open Source library • Toolkit. \n",
      "1 Introduction \n",
      "Deep Learning(DL)-based approaches are the state-of-the-art for a wide range of \n",
      "documen t image analysis (DIA) tasks including documen t image classification [ 11,\n"
     ]
    }
   ],
   "source": [
    "# PDF 로더 초기화, 이미지 추출 옵션 활성화\n",
    "loader = PyPDFLoader(FILE_PATH, extract_images=True)\n",
    "\n",
    "# PDF 페이지 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 페이지 내용 접근\n",
    "# print(docs[4].page_content[:300])\n",
    "print(docs[0].page_content[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0fe6caa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'author', 'moddate', 'title', 'source', 'total_pages', 'page', 'page_label']\n",
      "\n",
      "[examples]\n",
      "producer     : Adobe Acrobat (64-bit) 25 Paper Capture Plug-in\n",
      "creator      : PyPDF\n",
      "creationdate : 2025-08-22T12:38:36+09:00\n",
      "author       : Heejin Park\n",
      "moddate      : 2025-08-22T12:47:11+09:00\n",
      "title        : C:\\Users\\park0\\Downloads\\2103.15348v2.pdf\n",
      "source       : ./data/2103_page1.pdf\n",
      "total_pages  : 1\n",
      "page         : 0\n",
      "page_label   : 1\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)\n",
    "\n",
    "# langchain의 버전에 따라서 메타데이터 출력 형식이 다를 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a191d5c",
   "metadata": {},
   "source": [
    "## PyMuPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88bca1",
   "metadata": {},
   "source": [
    "**PyMuPDF** 는 속도 최적화가 되어 있으며, PDF 및 해당 페이지에 대한 자세한 메타데이터를 포함하고 있습니다. 페이지 당 하나의 문서를 반환합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ac56d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6dbc04bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일 로드\n",
    "# FILE_PATH = \"./data/SPRI_AI_Brief_2023년12월호_F.pdf\"\n",
    "FILE_PATH = \"./data/2103_page1.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47e7a947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout Parser: A Unified Toolkit for Deep \n",
      "Learning Based Document Image Analysis \n",
      "IZOZ \n",
      "unr \n",
      "It \n",
      "Zejiang Shen1 詞), Ruochen Zhang2, Melissa Dell3, Benj amin Charles Germain \n",
      "Lee4, Jacob Carlson3, and Weining Li 5 \n",
      "1 Allen Institut e for AI \n",
      "shannons©allenai .org \n",
      "2 Brown University \n",
      "ruochen_zhang©brown.edu \n",
      "3 Harvard University \n",
      "{meli ssadell, j acob_carlson}©f as.harvard.edu \n",
      "4 University of Washington \n",
      "bcgl©cs.washi ngton.edu \n",
      "5 University of Waterloo \n",
      "w422li©u멀at erloo.ca \n",
      "[AU\n",
      "·s~] \n",
      "현\n",
      "/\n",
      "o\n",
      "o寸\n",
      "E\n",
      "S\n",
      "I\n",
      "•\n",
      "E\n",
      "O\n",
      "I\n",
      "N\n",
      "A\n",
      "!\n",
      "X\n",
      "1\n",
      "B\n",
      " \n",
      "Abst ract . Recent advances in document image analysis (DIA) have been \n",
      "primarily driven by t he application of neural networks. Ideally, research \n",
      "outcomes could be easily deployed in production and extended for further \n",
      "investigation. However, various fact ors like loosely organized codebases \n",
      "and sophisticated model configurations complicat e t he easy reuse of im-\n",
      "portant innovations by a wide audience. Though there have been on-going \n",
      "effort s t o improve reusability and simplify deep learning (DL) model \n",
      "development in disciplines like natural language processing and computer \n",
      "vision, none of t hem are optimized for challenges in t he domain of DIA. \n",
      "This represents a major gap in t he existing toolkit, as DIA is central to \n",
      "academic research across a wide range of disciplines in the social sciences \n",
      "and humanities. This paper int roduces Layout Parser, an open-source \n",
      "library for st reamlining the usage of DL in DIA research and applica-\n",
      "tions. The core Layout Parser library comes with a set of simple and \n",
      "int uitive interfaces for applying and customizing DL models for layout de-\n",
      "tection, character recognition, and many ot her document processing tasks. \n",
      "To promote ext ensibility, Layout Parser also incorporates a community \n",
      "platform for sharing bot h pre-trained models and full document digiti-\n",
      "zation pipelines. We demonstrate that Layout Parser is helpful for bot h \n",
      "lightweight and large-scale digitization pipelines in real-word use cases. \n",
      "The library is publicly available at https : //layout-parser . github . i o. \n",
      "Key words: Document Image Analysis • Deep Learning • Layout Analysis \n",
      "• Character Recognition • Open Source library • Toolkit. \n",
      "1 Int roduction \n",
      "Deep Learning(DL)-based approaches are t he st at e-of-the-art for a wide range of \n",
      "document image analysis (DIA) t asks including document image classification [ 11,\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# PyMuPDF 로더 인스턴스 생성\n",
    "loader = PyMuPDFLoader(FILE_PATH)\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bbca8760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'source', 'file_path', 'total_pages', 'format', 'title', 'author', 'subject', 'keywords', 'moddate', 'trapped', 'modDate', 'creationDate', 'page']\n",
      "\n",
      "[examples]\n",
      "producer     : Adobe Acrobat (64-bit) 25 Paper Capture Plug-in\n",
      "creator      : \n",
      "creationdate : 2025-08-22T12:38:36+09:00\n",
      "source       : ./data/2103_page1.pdf\n",
      "file_path    : ./data/2103_page1.pdf\n",
      "total_pages  : 1\n",
      "format       : PDF 1.7\n",
      "title        : C:\\Users\\park0\\Downloads\\2103.15348v2.pdf\n",
      "author       : Heejin Park\n",
      "subject      : \n",
      "keywords     : \n",
      "moddate      : 2025-08-22T12:47:11+09:00\n",
      "trapped      : \n",
      "modDate      : D:20250822124711+09'00'\n",
      "creationDate : D:20250822123836+09'00'\n",
      "page         : 0\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89745c9",
   "metadata": {},
   "source": [
    "## Unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72199f11",
   "metadata": {},
   "source": [
    "[Unstructured](https://unstructured-io.github.io/unstructured/)는 Markdown이나 PDF와 같은 비구조화된 또는 반구조화된 파일 형식을 다루기 위한 공통 인터페이스를 지원합니다. \n",
    "\n",
    "LangChain의 [UnstructuredPDFLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.UnstructuredPDFLoader.html)는 Unstructured와 통합되어 PDF 문서를 LangChain [Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html) 객체로 파싱합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6cc687b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "# !pip install -qU unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74ec1b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ pdfminer.six==20220319 설치 완료\n",
      "✓ unstructured[pdf]==0.10.30 설치 완료\n",
      "\n",
      "패키지 설치 완료. 커널을 재시작하고 다시 시도해주세요.\n"
     ]
    }
   ],
   "source": [
    "# pdfminer 호환성 문제 해결을 위한 패키지 설치\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "def install_compatible_packages():\n",
    "    \"\"\"호환되는 버전의 패키지들 설치\"\"\"\n",
    "    packages = [\n",
    "        \"pdfminer.six==20220319\",  # 호환되는 구 버전\n",
    "        \"unstructured[pdf]==0.10.30\",  # 호환되는 unstructured 버전\n",
    "    ]\n",
    "\n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "            print(f\"✓ {package} 설치 완료\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"✗ {package} 설치 실패: {e}\")\n",
    "\n",
    "\n",
    "# 호환 패키지 설치 실행\n",
    "install_compatible_packages()\n",
    "print(\"\\n패키지 설치 완료. 커널을 재시작하고 다시 시도해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "04780e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일 로드\n",
    "# FILE_PATH = \"./data/SPRI_AI_Brief_2023년12월호_F.pdf\"\n",
    "FILE_PATH = \"./data/2103_page1.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40cb362e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IZOZ\n",
      "\n",
      "unr\n",
      "\n",
      "It\n",
      "\n",
      "[AU\n",
      "\n",
      "s~]\n",
      "\n",
      "현 / o 寸 E o S I • E O I N A ! X 1 B\n",
      "\n",
      "Layout Parser: A Unified Toolkit for Deep Learni n g Based Document Image Analysi s\n",
      "\n",
      "Zejiang Shen1 詞), Ruochen Zhang2, Melissa Dell3, Benj ami n Charles Germai n Lee4, Jacob Carlson3, and Wei n i n g Li 5\n",
      "\n",
      "1 Allen Institut e for AI shannons©allenai .org 2 Brown University ruochen_zhang©brown.edu 3 Harvard University {meli ssadell, j acob_carlson}©f as.harvard.edu 4 University of Washi ngton bcgl©cs.washi ngton.edu 5 University of Wat erloo\n",
      "\n",
      "w422 li ©u멀at erloo.ca\n",
      "\n",
      "Abst ract . Recent advances in document image analysis (DIA) have been primarily driven by t he application of neural net works. Ideally, research out comes could be easily deployed i n production and ext ended for furt her investigation. However, various fact ors like loosely organized codebases and sophisticat ed model configurations complicat e t he easy reuse of im port ant innovations by a wide audience. Though t here have been on-goi ng effort s t o improve reusability and simplify deep learni ng (DL) model development in disciplines like nat ural language processing and comput er vision, none of t hem are optimized for challenges i n t he domai n of DIA. This represent s a maj or gap i n t he existing t oolkit, as DIA is cent ral t o academic research across a wide range of disciplines i n t he social sciences and humanities. This paper i nt roduces Layout Parser, an open-source library for st reamli ni ng t he usage of DL i n DIA research and applica tions. The core Layout Parser library comes with a set of simple and int uitive int erfaces for applying and cust omizing DL models for layout de t ection, charact er recognition, and many ot her document processing t asks. To promot e ext ensi bility, Layout Parser also i ncorporat es a community platform for shari ng bot h pre-t rained models and full document digiti zation pipelines. We demonst rat e t hat Layout Parser is helpful for bot h light weight and large-scale digitization pipelines i n real-word use cases. The library is publicly available at https : //layout-parser . github . i o.\n",
      "\n",
      "Key words: Document Image Analysis • Deep Learni ng • Layout Analysis • Charact er Recognition • Open Source library • Toolkit.\n",
      "\n",
      "1\n",
      "\n",
      "Int roduction\n",
      "\n",
      "Deep Learni ng(DL)-based approaches are t he st at e-of-the-art for a wide range of document image analysis (DIA) t asks i ncludi ng document i mage classification [ 11,\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "# UnstructuredPDFLoader 인스턴스 생성\n",
    "loader = UnstructuredPDFLoader(FILE_PATH)\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e354a080",
   "metadata": {},
   "source": [
    "IZOZ\n",
    "\n",
    "unr\n",
    "\n",
    "It\n",
    "\n",
    "[AU\n",
    "\n",
    "s~]\n",
    "\n",
    "현 / o 寸 E o S I • E O I N A ! X 1 B\n",
    "\n",
    "Layout Parser: A Unified Toolkit for Deep Learni n g Based Document Image Analysi s\n",
    "\n",
    "Zejiang Shen1 詞), Ruochen Zhang2, Melissa Dell3, Benj ami n Charles Germai n Lee4, Jacob Carlson3, and Wei n i n g Li 5\n",
    "\n",
    "1 Allen Institut e for AI shannons©allenai .org 2 Brown University ruochen_zhang©brown.edu 3 Harvard University {meli ssadell, j acob_carlson}©f as.harvard.edu 4 University of Washi ngton bcgl©cs.washi ngton.edu 5 University of Wat erloo\n",
    "\n",
    "w422 li ©u멀at erloo.ca\n",
    "\n",
    "Abst ract . Recent advances in document image analysis (DIA) have been primarily driven by t he application of neural net works. Ideally, research out comes could be easily deployed i n production and ext ended for furt her investigation. However, various fact ors like loosely organized codebases and sophisticat ed model configurations complicat e t he easy reuse of im port ant innovations by a wide audience. Though t here have been on-goi ng effort s t o improve reusability and simplify deep learni ng (DL) model development in disciplines like nat ural language processing and comput er vision, none of t hem are optimized for challenges i n t he domai n of DIA. This represent s a maj or gap i n t he existing t oolkit, as DIA is cent ral t o academic research across a wide range of disciplines i n t he social sciences and humanities. This paper i nt roduces Layout Parser, an open-source library for st reamli ni ng t he usage of DL i n DIA research and applica tions. The core Layout Parser library comes with a set of simple and int uitive int erfaces for applying and cust omizing DL models for layout de t ection, charact er recognition, and many ot her document processing t asks. To promot e ext ensi bility, Layout Parser also i ncorporat es a community platform for shari ng bot h pre-t rained models and full document digiti zation pipelines. We demonst rat e t hat Layout Parser is helpful for bot h light weight and large-scale digitization pipelines i n real-word use cases. The library is publicly available at https : //layout-parser . github . i o.\n",
    "\n",
    "Key words: Document Image Analysis • Deep Learni ng • Layout Analysis • Charact er Recognition • Open Source library • Toolkit.\n",
    "\n",
    "1\n",
    "\n",
    "Int roduction\n",
    "\n",
    "Deep Learni ng(DL)-based approaches are t he st at e-of-the-art for a wide range of document image analysis (DIA) t asks i ncludi ng document i mage classification [ 11,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "926b929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['source']\n",
      "\n",
      "[examples]\n",
      "source : ./data/2103_page1.pdf\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3115d62b",
   "metadata": {},
   "source": [
    "내부적으로 비정형에서는 텍스트 청크마다 서로 다른 \"**요소**\"를 만듭니다. 기본적으로 이들은 결합되어 있지만 `mode=\"elements\"`를 지정하여 쉽게 분리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6f97007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IZOZ\n"
     ]
    }
   ],
   "source": [
    "# UnstructuredPDFLoader 인스턴스 생성(mode=\"elements\")\n",
    "loader = UnstructuredPDFLoader(FILE_PATH, mode=\"elements\")\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ab703e",
   "metadata": {},
   "source": [
    "이 특정 문서에 대한 전체 요소 유형 집합을 참조하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0fd7976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ListItem', 'NarrativeText', 'Title', 'UncategorizedText'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(doc.metadata[\"category\"] for doc in docs)  # 데이터 카테고리 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ec0c096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['source', 'coordinates', 'filename', 'file_directory', 'last_modified', 'filetype', 'page_number', 'category', 'element_id']\n",
      "\n",
      "[examples]\n",
      "source         : ./data/2103_page1.pdf\n",
      "coordinates    : {'points': ((25.44, 207.87349999999992), (25.44, 218.37349999999992), (62.67233920000001, 218.37349999999992), (62.67233920000001, 207.87349999999992)), 'system': 'PixelSpace', 'layout_width': 595.32, 'layout_height': 841.92}\n",
      "filename       : 2103_page1.pdf\n",
      "file_directory : ./data\n",
      "last_modified  : 2025-08-22T13:08:42\n",
      "filetype       : application/pdf\n",
      "page_number    : 1\n",
      "category       : Title\n",
      "element_id     : d480e4bbfe8892846ed91c12a6c4fe67\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5097872",
   "metadata": {},
   "source": [
    "## PyPDFium2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "18c84bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout Parser: A Unified Toolkit for Deep \n",
      "Learning Based Document Image Analysis \n",
      "IZOZ \n",
      "unr \n",
      "I\n",
      "t \n",
      "Zejiang Shen1 詞), Ruochen Zhang2, Melissa Dell3, Benj amin Charles Germain \n",
      "Lee4, Jacob Carlson3, and Wei ning Li 5 \n",
      "1 Allen Institut e for AI \n",
      "shannons©allenai .org \n",
      "2 Brown University \n",
      "ruochen_zhang©brown.edu \n",
      "3 Harvard University \n",
      "{meli ssadell, j acob_carlson}©f as.harvard.edu \n",
      "4 University of Washington \n",
      "bcgl©cs.washi ngton.edu \n",
      "5 University of Wat erloo \n",
      "w422li©u erloo.ca \n",
      "[AU\n",
      "·\n",
      "s~] \n",
      "Abst ract . Recent advances in document image analysis (DIA) have been \n",
      "primarily driven by t he application of neural networks. Ideally, research \n",
      "out comes could be easily deployed in production and ext ended for furt her \n",
      "investigation. However, various fact ors like loosely organized codebases \n",
      "and sophisticat ed model configurations complicat e t he easy reuse of im\u0002port ant innovations by a wide audience. Though t here have been on-going \n",
      "efforts t o improve reusability and simplify deep learning (DL) model \n",
      "development in disciplines like nat ural language processing and comput er \n",
      "vision, none of t hem are optimized for challenges in t he domain of DIA. \n",
      "This represents a maj or gap in t he existing t oolkit, as DIA is central t o \n",
      "academic research across a wide range of disciplines in t he social sciences \n",
      "and humanities. This paper introduces Layout Parser, an open-source \n",
      "library for streamlining t he usage of DL in DIA research and applica\u0002tions. The core Layout Parser library comes with a set of simple and \n",
      "int uitive int erfaces for applying and cust omizing DL models for layout de\u0002t ection, charact er recognition, and many ot her document processing t asks. \n",
      "To promot e ext ensibility, Layout Parser also incorporat es a community \n",
      "platform for sharing bot h pre-trained models and full document digiti\u0002zation pipelines. We demonstrat e t hat Layout Parser is helpful for bot h \n",
      "lightweight and large-scale digitization pipelines in real-word use cases. \n",
      "The library is publicly available at https : //layout-parser . github . i o. \n",
      "Key words: Document Image Analysis • Deep Learning • Layout Analysis \n",
      "• Charact er Recognition • Open Source library • Toolkit. \n",
      "1 Introduction \n",
      "Deep Learni ng(DL)-based approaches are t he st at e-of-the-art for a wide range of \n",
      "document image analysis (DIA) t asks includi ng document image classification [ 11,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFium2Loader\n",
    "\n",
    "# PyPDFium2 로더 인스턴스 생성\n",
    "loader = PyPDFium2Loader(FILE_PATH)\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d4cd8966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'title', 'author', 'subject', 'keywords', 'moddate', 'source', 'total_pages', 'page']\n",
      "\n",
      "[examples]\n",
      "producer     : Adobe Acrobat (64-bit) 25 Paper Capture Plug-in\n",
      "creator      : \n",
      "creationdate : 2025-08-22T12:38:36+09:00\n",
      "title        : C:\\Users\\park0\\Downloads\\2103.15348v2.pdf\n",
      "author       : Heejin Park\n",
      "subject      : \n",
      "keywords     : \n",
      "moddate      : 2025-08-22T12:47:11+09:00\n",
      "source       : ./data/2103_page1.pdf\n",
      "total_pages  : 1\n",
      "page         : 0\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2b2a6a",
   "metadata": {},
   "source": [
    "## PDFMiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5feac159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout Parser:  A  Unified Toolkit for Deep \n",
      "Learni n g Based Document  Image  Analysi s \n",
      "\n",
      "Zejiang  Shen1  詞), Ruochen  Zhang2,  Melissa Dell3,  Benj ami n  Charles  Germai n \n",
      "Lee4,  Jacob  Carlson3,  and Wei n i n g  Li 5 \n",
      "\n",
      "1  Allen  Institut e  for  AI \n",
      "shannons©allenai .org \n",
      "2  Brown University \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFMinerLoader\n",
    "\n",
    "# PDFMiner 로더 인스턴스 생성\n",
    "loader = PDFMinerLoader(FILE_PATH)\n",
    "\n",
    "# 데이터 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])\n",
    "\n",
    "# 한글 문서의 경우 띄어쓰기가 2칸씩 될 수 있으므로 주의가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65a85f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['producer', 'creator', 'creationdate', 'author', 'moddate', 'title', 'total_pages', 'source']\n",
      "\n",
      "[examples]\n",
      "producer     : Adobe Acrobat (64-bit) 25 Paper Capture Plug-in\n",
      "creator      : PDFMiner\n",
      "creationdate : 2025-08-22T12:38:36+09:00\n",
      "author       : Heejin Park\n",
      "moddate      : 2025-08-22T12:47:11+09:00\n",
      "title        : C:\\Users\\park0\\Downloads\\2103.15348v2.pdf\n",
      "total_pages  : 1\n",
      "source       : ./data/2103_page1.pdf\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d918ef7",
   "metadata": {},
   "source": [
    "**PDFMiner**를 사용하여 HTML 텍스트 생성\n",
    "\n",
    "이 방법은 출력된 HTML 콘텐츠를 `BeautifulSoup`을 통해 파싱함으로써 글꼴 크기, 페이지 번호, PDF 헤더/푸터 등에 대한 보다 구조화되고 풍부한 정보를 얻을 수 있게 하여 텍스트를 의미론적으로 섹션으로 분할하는 데 도움이 될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d299c2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head>\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html\">\n",
      "</head><body>\n",
      "<span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:595px; height:841px;\"></span>\n",
      "<div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div>\n",
      "<div style=\"position:absolute; border\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFMinerPDFasHTMLLoader\n",
    "\n",
    "# PDFMinerPDFasHTMLLoader 인스턴스 생성\n",
    "loader = PDFMinerPDFasHTMLLoader(FILE_PATH)\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0aacfd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['source']\n",
      "\n",
      "[examples]\n",
      "source : ./data/2103_page1.pdf\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "df728c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(docs[0].page_content, \"html.parser\")  # HTML 파서 초기화\n",
    "content = soup.find_all(\"div\")  # 모든 div 태그 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15d75111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cur_fs = None\n",
    "cur_text = \"\"\n",
    "snippets = []  # 동일한 글꼴 크기의 모든 스니펫 수집\n",
    "for c in content:\n",
    "    sp = c.find(\"span\")\n",
    "    if not sp:\n",
    "        continue\n",
    "    st = sp.get(\"style\")\n",
    "    if not st:\n",
    "        continue\n",
    "    fs = re.findall(\"font-size:(\\d+)px\", st)\n",
    "    if not fs:\n",
    "        continue\n",
    "    fs = int(fs[0])\n",
    "    if not cur_fs:\n",
    "        cur_fs = fs\n",
    "    if fs == cur_fs:\n",
    "        cur_text += c.text\n",
    "    else:\n",
    "        snippets.append((cur_text, cur_fs))\n",
    "        cur_fs = fs\n",
    "        cur_text = c.text\n",
    "snippets.append((cur_text, cur_fs))\n",
    "# 중복 스니펫 제거 전략 추가 가능성 (PDF의 헤더/푸터가 여러 페이지에 걸쳐 나타나므로 중복 발견 시 중복 정보로 간주 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8061d2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='It \n",
      "' metadata={'heading': 'unr \\n', 'content_font': 7, 'heading_font': 19, 'source': './data/2103_page1.pdf'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "cur_idx = -1\n",
    "semantic_snippets = []\n",
    "# 제목 가정: 높은 글꼴 크기\n",
    "for s in snippets:\n",
    "    # 새 제목 판별: 현재 스니펫 글꼴 > 이전 제목 글꼴\n",
    "    if (\n",
    "        not semantic_snippets\n",
    "        or s[1] > semantic_snippets[cur_idx].metadata[\"heading_font\"]\n",
    "    ):\n",
    "        metadata = {\"heading\": s[0], \"content_font\": 0, \"heading_font\": s[1]}\n",
    "        metadata.update(docs[0].metadata)\n",
    "        semantic_snippets.append(Document(page_content=\"\", metadata=metadata))\n",
    "        cur_idx += 1\n",
    "        continue\n",
    "\n",
    "    # 동일 섹션 내용 판별: 현재 스니펫 글꼴 <= 이전 내용 글꼴\n",
    "    if (\n",
    "        not semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
    "        or s[1] <= semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
    "    ):\n",
    "        semantic_snippets[cur_idx].page_content += s[0]\n",
    "        semantic_snippets[cur_idx].metadata[\"content_font\"] = max(\n",
    "            s[1], semantic_snippets[cur_idx].metadata[\"content_font\"]\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # 새 섹션 생성 조건: 현재 스니펫 글꼴 > 이전 내용 글꼴, 이전 제목 글꼴 미만\n",
    "    metadata = {\"heading\": s[0], \"content_font\": 0, \"heading_font\": s[1]}\n",
    "    metadata.update(docs[0].metadata)\n",
    "    semantic_snippets.append(Document(page_content=\"\", metadata=metadata))\n",
    "    cur_idx += 1\n",
    "\n",
    "print(semantic_snippets[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0740f50",
   "metadata": {},
   "source": [
    "## PyPDF 디렉토리\n",
    "\n",
    "디렉토리에서 PDF를 로드하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93bbbbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# 디렉토리 경로\n",
    "loader = PyPDFDirectoryLoader(\"data/\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "# 문서의 개수 출력\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "231ffd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout Parser: A Unified Toolkit for Deep\n",
      "Learning Based Document Image Analysis\n",
      "Zejiang Shen1 詞), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain\n",
      "Lee4, Jacob Carlson3, and Weining Li5\n",
      "1 Allen Institute for AI\n",
      "IZOZ\n",
      "shannons©allenai .org\n",
      "2 Brown University\n",
      "ruochen_zhang©brown.edu\n",
      "unr\n",
      "3 Harvard University\n",
      "{meli ssadell,jacob_carlson}©fas.harvard.edu\n",
      "4 University of Washington\n",
      "bcgl©cs.washington.edu\n",
      "I\n",
      "t 5 University of Waterloo\n",
      "w422li©u멀aterloo.ca\n",
      "[AU\n",
      "Abstract . Recent advances in document image analysis (DIA) have been\n",
      "· s~] primarily driven by the application of neural networks. Ideally, research\n",
      "outcomes could be easily deployed in production and extended for further\n",
      "investigation. However, various factors like loosely organized codebases\n",
      "and sophisticated model configurations complicate the easy reuse of im\n",
      "현 portant innovations by a wide audience. Though there have been on-going\n",
      "/ efforts to improve reusability and simplify deep learning (DL) model\n",
      "development in disciplines like natural language processing and computer\n",
      "寸o\n",
      "vision, none of them are optimized for challenges in the domain of DIA.\n",
      "Eo\n",
      "This represents a major gap in the existing toolkit, as DIA is central to\n",
      "S academic research across a wide range of disciplines in the social sciences\n",
      "and humanities. This paper introduces LayoutParser, an open-source\n",
      "I\n",
      "library for streamlining the usage of DL in DIA research and applica\n",
      "•\n",
      "tions. The core LayoutParser library comes with a set of simple and\n",
      "E intuitive interfaces for applying and customizing DL models for layout de\n",
      "O tection, character recognition, and many other document processing tasks.\n",
      "To promote extensibility, LayoutParser also incorporates a community\n",
      "I\n",
      "platform for sharing both pre-trained models and full document digiti\n",
      "N zation pipelines. We demonstrate that LayoutParser is helpful for both\n",
      "A lightweight and large-scale digitization pipelines in real-word use cases.\n",
      "The library is publicly available at https : //layout-parser . github . io.\n",
      "!\n",
      "X Keywords: Document Image Analysis • Deep Learning • Layout Analysis\n",
      "1 • Character Recognition • Open Source library • Toolkit.\n",
      "B\n",
      "1\n",
      "Introduction\n",
      "Deep Learning(DL)-based approaches are the state-of-the-art for a wide range of\n",
      "document image analysis (DIA) tasks including document image classification [1 1,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 문서의 내용 출력\n",
    "print(docs[0].page_content[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05c68b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.5 (Windows)', 'creationdate': '2024-12-17T10:16:15+09:00', 'moddate': '2024-12-17T10:18:06+09:00', 'trapped': '/False', 'source': 'data\\\\planner.pdf', 'total_pages': 111, 'page': 28, 'page_label': '29'}\n"
     ]
    }
   ],
   "source": [
    "# metadata 출력\n",
    "print(docs[50].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb92d77",
   "metadata": {},
   "source": [
    "## PDFPlumber\n",
    "\n",
    "PyMuPDF와 마찬가지로, 출력 문서는 PDF와 그 페이지에 대한 자세한 메타데이터를 포함하며, 페이지 당 하나의 문서를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e97bd7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layout Parser: A Unified Toolkit for Deep\n",
      "Learning Based Document Image Analysis\n",
      "Zejiang Shen1 詞), Ruochen Zhang2, Melissa Dell3, Benjamin Charles Germain\n",
      "Lee4, Jacob Carlson3, and Weining Li5\n",
      "1 Allen Institute for AI\n",
      "IZOZ\n",
      "shannons©allenai .org\n",
      "2 Brown University\n",
      "ruochen_zhang©brown.edu\n",
      "unr\n",
      "3 Harvard University\n",
      "{meli ssadell,jacob_carlson}©fas.harvard.edu\n",
      "4 University of Washington\n",
      "bcgl©cs.washington.edu\n",
      "I\n",
      "t 5 University of Waterloo\n",
      "w422li©u멀aterloo.ca\n",
      "[AU\n",
      "Abstract . Recent advances in document image analysis (DIA) have been\n",
      "· s~] primarily driven by the application of neural networks. Ideally, research\n",
      "outcomes could be easily deployed in production and extended for further\n",
      "investigation. However, various factors like loosely organized codebases\n",
      "and sophisticated model configurations complicate the easy reuse of im\n",
      "현 portant innovations by a wide audience. Though there have been on-going\n",
      "/ efforts to improve reusability and simplify deep learning (DL) model\n",
      "development in disciplines like natural language processing and computer\n",
      "寸o\n",
      "vision, none of them are optimized for challenges in the domain of DIA.\n",
      "Eo\n",
      "This represents a major gap in the existing toolkit, as DIA is central to\n",
      "S academic research across a wide range of disciplines in the social sciences\n",
      "and humanities. This paper introduces LayoutParser, an open-source\n",
      "I\n",
      "library for streamlining the usage of DL in DIA research and applica\n",
      "•\n",
      "tions. The core LayoutParser library comes with a set of simple and\n",
      "E intuitive interfaces for applying and customizing DL models for layout de\n",
      "O tection, character recognition, and many other document processing tasks.\n",
      "To promote extensibility, LayoutParser also incorporates a community\n",
      "I\n",
      "platform for sharing both pre-trained models and full document digiti\n",
      "N zation pipelines. We demonstrate that LayoutParser is helpful for both\n",
      "A lightweight and large-scale digitization pipelines in real-word use cases.\n",
      "The library is publicly available at https : //layout-parser . github . io.\n",
      "!\n",
      "X Keywords: Document Image Analysis • Deep Learning • Layout Analysis\n",
      "1 • Character Recognition • Open Source library • Toolkit.\n",
      "B\n",
      "1\n",
      "Introduction\n",
      "Deep Learning(DL)-based approaches are the state-of-the-art for a wide range of\n",
      "document image analysis (DIA) tasks including document image classification [1 1,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "\n",
    "# PDF 문서 로더 인스턴스 생성\n",
    "loader = PDFPlumberLoader(FILE_PATH)\n",
    "\n",
    "# 문서 로딩\n",
    "docs = loader.load()\n",
    "\n",
    "# 첫 번째 문서 데이터 접근\n",
    "print(docs[0].page_content[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e250ac42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['source', 'file_path', 'page', 'total_pages', 'Author', 'CreationDate', 'ModDate', 'Producer', 'Title']\n",
      "\n",
      "[examples]\n",
      "source       : ./data/2103_page1.pdf\n",
      "file_path    : ./data/2103_page1.pdf\n",
      "page         : 0\n",
      "total_pages  : 1\n",
      "Author       : Heejin Park\n",
      "CreationDate : D:20250822123836+09'00'\n",
      "ModDate      : D:20250822124711+09'00'\n",
      "Producer     : Adobe Acrobat (64-bit) 25 Paper Capture Plug-in\n",
      "Title        : C:\\Users\\park0\\Downloads\\2103.15348v2.pdf\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c637a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-Us6BDj1P-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
