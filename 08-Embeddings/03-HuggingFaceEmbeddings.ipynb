{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 허깅페이스 임베딩(HuggingFace Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH08-Embeddings\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH08-Embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ./cache/ 경로에 다운로드 받도록 설정\n",
    "# 기본값 경로에 저장하게 되면 차지하는 용량이 매우 커지므로 경로를 따로 설정해줘야 함!\n",
    "os.environ[\"HF_HOME\"] = \"./cache/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 샘플 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"안녕, 만나서 반가워.\",\n",
    "    \"LangChain simplifies the process of building applications with large language models\",\n",
    "    \"랭체인 한국어 튜토리얼은 LangChain의 공식 문서, cookbook 및 다양한 실용 예제를 바탕으로 하여 사용자가 LangChain을 더 쉽고 효과적으로 활용할 수 있도록 구성되어 있습니다. \",\n",
    "    \"LangChain은 초거대 언어모델로 애플리케이션을 구축하는 과정을 단순화합니다.\",\n",
    "    \"Retrieval-Augmented Generation (RAG) is an effective technique for improving AI responses.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**참고(Reference)**\n",
    "\n",
    "![](./images/top-ranked-embeddings.png)\n",
    "\n",
    "- [(출처) Kor-IR: 한국어 검색을 위한 임베딩 벤치마크](https://github.com/teddylee777/Kor-IR?tab=readme-ov-file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace Endpoint Embedding\n",
    "\n",
    "`HuggingFaceEndpointEmbeddings` 는 내부적으로 InferenceClient를 사용하여 임베딩을 계산한다는 점에서 HuggingFaceEndpoint가 LLM에서 수행하는 것과 매우 유사합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
    "\n",
    "model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
    "\n",
    "hf_embeddings = HuggingFaceEndpointEmbeddings(\n",
    "    model=model_name,\n",
    "    task=\"feature-extraction\",\n",
    "    huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document 임베딩은 `embed_documents()` 를 호출하여 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 141 ms\n",
      "Wall time: 5.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Document Embedding 수행\n",
    "embedded_documents = hf_embeddings.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HuggingFace Endpoint Embedding]\n",
      "Model: \t\tintfloat/multilingual-e5-large-instruct\n",
      "Dimension: \t1024\n"
     ]
    }
   ],
   "source": [
    "print(\"[HuggingFace Endpoint Embedding]\")\n",
    "print(f\"Model: \\t\\t{model_name}\")\n",
    "print(f\"Dimension: \\t{len(embedded_documents[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Embedding 수행\n",
    "embedded_query = hf_embeddings.embed_query(\"LangChain 에 대해서 알려주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유사도 계산\n",
    "\n",
    "**벡터 내적을 통한 유사도 계산**\n",
    "- 벡터 내적(dot product)을 사용하여 유사도를 계산합니다. \n",
    "\n",
    "- 유사도 계산 공식:\n",
    "\n",
    "$$ \\text{similarities} = \\mathbf{query} \\cdot \\mathbf{documents}^T $$\n",
    "\n",
    "#### 벡터 내적의 수학적 의미\n",
    "\n",
    "**벡터 내적 정의**\n",
    "\n",
    "벡터 $\\mathbf{a}$와 $\\mathbf{b}$의 내적은 다음과 같이 정의됩니다:\n",
    "$$ \\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=1}^{n} a_i b_i $$\n",
    "\n",
    "**코사인 유사도와의 관계**\n",
    "\n",
    "벡터 내적은 다음과 같은 성질을 가집니다.\n",
    "$$ \\mathbf{a} \\cdot \\mathbf{b} = \\|\\mathbf{a}\\| \\|\\mathbf{b}\\| \\cos \\theta $$\n",
    "\n",
    "여기서,\n",
    "- $\\|\\mathbf{a}\\|$와 $\\|\\mathbf{b}\\|$는 각각 벡터 $\\mathbf{a}$와 $\\mathbf{b}$의 크기(노름, Euclidean norm)입니다.\n",
    "- $\\theta$는 두 벡터 사이의 각도입니다.\n",
    "- $\\cos \\theta$는 두 벡터 사이의 코사인 유사도입니다.\n",
    "\n",
    "**벡터 내적의 유사도 해석**\n",
    "내적 값이 클수록 (양의 큰 값일수록),\n",
    "- 두 벡터의 크기($\\|\\mathbf{a}\\|$와 $\\|\\mathbf{b}\\|$)가 크고,\n",
    "- 두 벡터 사이의 각도($\\theta$)가 작으며 ($\\cos \\theta$가 1에 가까움),\n",
    "\n",
    "이는 두 벡터가 유사한 방향을 가리키고, 크기가 클수록 더 유사하다는 것을 의미합니다.\n",
    "\n",
    "**벡터의 크기(노름) 계산**\n",
    "\n",
    "Euclidean norm 정의\n",
    "벡터 $\\mathbf{a} = [a_1, a_2, \\ldots, a_n]$에 대해, Euclidean norm $\\|\\mathbf{a}\\|$는 다음과 같이 정의됩니다:\n",
    "$$ \\|\\mathbf{a}\\| = \\sqrt{a_1^2 + a_2^2 + \\cdots + a_n^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "query 와 embedding_document 간의 유사도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84186325, 0.8650231 , 0.86470289, 0.89564874, 0.7684733 ])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 질문(embedded_query): LangChain 에 대해서 알려주세요.\n",
    "np.array(embedded_query) @ np.array(embedded_documents).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_idx = (np.array(embedded_query) @ np.array(embedded_documents).T).argsort()[::-1]\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Query] LangChain 에 대해서 알려주세요.\n",
      "====================================\n",
      "[0] LangChain은 초거대 언어모델로 애플리케이션을 구축하는 과정을 단순화합니다.\n",
      "\n",
      "[1] LangChain simplifies the process of building applications with large language models\n",
      "\n",
      "[2] 랭체인 한국어 튜토리얼은 LangChain의 공식 문서, cookbook 및 다양한 실용 예제를 바탕으로 하여 사용자가 LangChain을 더 쉽고 효과적으로 활용할 수 있도록 구성되어 있습니다. \n",
      "\n",
      "[3] 안녕, 만나서 반가워.\n",
      "\n",
      "[4] Retrieval-Augmented Generation (RAG) is an effective technique for improving AI responses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"[Query] LangChain 에 대해서 알려주세요.\\n====================================\")\n",
    "for i, idx in enumerate(sorted_idx):\n",
    "    print(f\"[{i}] {texts[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace Embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `intfloat/multilingual-e5-large-instruct`\n",
    "\n",
    "- [intfloat/multilingual-e5-large-instruct](https://huggingface.co/intfloat/multilingual-e5-large-instruct)\n",
    "- [intfloat/multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from sentence-transformers) (4.55.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
    "# model_name = \"intfloat/multilingual-e5-large\"\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs={\"device\": \"cpu\"},  # cuda, cpu: cpu에서 사용 /mps: 맥북에서 사용\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Document\n",
    "embedded_documents1 = hf_embeddings.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \t\tintfloat/multilingual-e5-large-instruct\n",
      "Dimension: \t1024\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model: \\t\\t{model_name}\")\n",
    "print(f\"Dimension: \\t{len(embedded_documents[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## BGE-M3 임베딩\n",
    "\n",
    "아래의 옵션 중 에러가 발생할 수 있는 옵션 설명\n",
    "\n",
    "- `{\"device\": \"mps\"}`: GPU 대신 MPS를 사용하여 임베딩 계산을 수행합니다. (Mac 사용자)\n",
    "- `{\"device\": \"cuda\"}`: GPU를 사용하여 임베딩 계산을 수행합니다. (Linux, Windows 사용자, 단 CUDA 설치 필요)\n",
    "- `{\"device\": \"cpu\"}`: CPU를 사용하여 임베딩 계산을 수행합니다. (모든 사용자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (2.2.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp311-cp311-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sba\\appdata\\local\\pypoetry\\cache\\virtualenvs\\langchain-kr-us6bdj1p-py3.11\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.8.0-cp311-cp311-win_amd64.whl (241.4 MB)\n",
      "   ---------------------------------------- 0.0/241.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 13.9/241.4 MB 72.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 22.0/241.4 MB 73.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 24.4/241.4 MB 40.6 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 41.7/241.4 MB 52.0 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 59.0/241.4 MB 58.7 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 77.3/241.4 MB 63.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 79.4/241.4 MB 55.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 95.9/241.4 MB 58.9 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 116.9/241.4 MB 63.8 MB/s eta 0:00:02\n",
      "   --------------------- ----------------- 134.2/241.4 MB 65.4 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 149.4/241.4 MB 66.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 166.7/241.4 MB 68.3 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 171.2/241.4 MB 64.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 175.4/241.4 MB 61.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 177.2/241.4 MB 59.0 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 177.7/241.4 MB 54.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 195.0/241.4 MB 55.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 205.8/241.4 MB 55.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 225.7/241.4 MB 57.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.4 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 241.4/241.4 MB 55.7 MB/s eta 0:00:00\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.2.0\n",
      "    Uninstalling torch-2.2.0:\n",
      "      Successfully uninstalled torch-2.2.0\n",
      "Successfully installed torch-2.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.17.0 requires torch==2.2.0, but you have torch 2.8.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m model_kwargs = {\u001b[33m\"\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m      5\u001b[39m encode_kwargs = {\u001b[33m\"\u001b[39m\u001b[33mnormalize_embeddings\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m hf_embeddings = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_kwargs\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\langchain_huggingface\\embeddings\\huggingface.py:98\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     96\u001b[39m     model_cls = sentence_transformers.SentenceTransformer\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28mself\u001b[39m._client = \u001b[43mmodel_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:327\u001b[39m, in \u001b[36mSentenceTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[39m\n\u001b[32m    309\u001b[39m has_modules = is_sentence_transformer_model(\n\u001b[32m    310\u001b[39m     model_name_or_path,\n\u001b[32m    311\u001b[39m     token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    314\u001b[39m     local_files_only=local_files_only,\n\u001b[32m    315\u001b[39m )\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    317\u001b[39m     has_modules\n\u001b[32m    318\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_model_type(\n\u001b[32m   (...)\u001b[39m\u001b[32m    325\u001b[39m     == \u001b[38;5;28mself\u001b[39m._model_config[\u001b[33m\"\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    326\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     modules, \u001b[38;5;28mself\u001b[39m.module_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    339\u001b[39m     modules = \u001b[38;5;28mself\u001b[39m._load_auto_model(\n\u001b[32m    340\u001b[39m         model_name_or_path,\n\u001b[32m    341\u001b[39m         token=token,\n\u001b[32m   (...)\u001b[39m\u001b[32m    349\u001b[39m         has_modules=has_modules,\n\u001b[32m    350\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:2253\u001b[39m, in \u001b[36mSentenceTransformer._load_sbert_model\u001b[39m\u001b[34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[39m\n\u001b[32m   2248\u001b[39m         module = module_class.load(local_path)\n\u001b[32m   2250\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2251\u001b[39m     \u001b[38;5;66;03m# Newer modules that support the new loading method are loaded with the new style\u001b[39;00m\n\u001b[32m   2252\u001b[39m     \u001b[38;5;66;03m# i.e. with many keyword arguments that can optionally be used by the modules\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2253\u001b[39m     module = \u001b[43mmodule_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2255\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Loading-specific keyword arguments\u001b[39;49;00m\n\u001b[32m   2256\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodule_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2261\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Module-specific keyword arguments\u001b[39;49;00m\n\u001b[32m   2262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2269\u001b[39m modules[module_config[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]] = module\n\u001b[32m   2270\u001b[39m module_kwargs[module_config[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m]] = module_config.get(\u001b[33m\"\u001b[39m\u001b[33mkwargs\u001b[39m\u001b[33m\"\u001b[39m, [])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:338\u001b[39m, in \u001b[36mTransformer.load\u001b[39m\u001b[34m(cls, model_name_or_path, subfolder, token, cache_folder, revision, local_files_only, trust_remote_code, model_kwargs, tokenizer_kwargs, config_kwargs, backend, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m    309\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    323\u001b[39m     **kwargs,\n\u001b[32m    324\u001b[39m ) -> Self:\n\u001b[32m    325\u001b[39m     init_kwargs = \u001b[38;5;28mcls\u001b[39m._load_init_kwargs(\n\u001b[32m    326\u001b[39m         model_name_or_path=model_name_or_path,\n\u001b[32m    327\u001b[39m         subfolder=subfolder,\n\u001b[32m   (...)\u001b[39m\u001b[32m    336\u001b[39m         backend=backend,\n\u001b[32m    337\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:87\u001b[39m, in \u001b[36mTransformer.__init__\u001b[39m\u001b[34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[39m\n\u001b[32m     84\u001b[39m     config_args = {}\n\u001b[32m     86\u001b[39m config, is_peft_model = \u001b[38;5;28mself\u001b[39m._load_config(model_name_or_path, cache_dir, backend, config_args)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_peft_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n\u001b[32m     90\u001b[39m     tokenizer_args[\u001b[33m\"\u001b[39m\u001b[33mmodel_max_length\u001b[39m\u001b[33m\"\u001b[39m] = max_seq_length\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:185\u001b[39m, in \u001b[36mTransformer._load_model\u001b[39m\u001b[34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001b[39m\n\u001b[32m    183\u001b[39m         \u001b[38;5;28mself\u001b[39m._load_mt5_model(model_name_or_path, config, cache_dir, **model_args)\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m         \u001b[38;5;28mself\u001b[39m.auto_model = \u001b[43mAutoModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m backend == \u001b[33m\"\u001b[39m\u001b[33monnx\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28mself\u001b[39m.auto_model = load_onnx_model(\n\u001b[32m    190\u001b[39m         model_name_or_path=model_name_or_path,\n\u001b[32m    191\u001b[39m         config=config,\n\u001b[32m    192\u001b[39m         task_name=\u001b[33m\"\u001b[39m\u001b[33mfeature-extraction\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    193\u001b[39m         **model_args,\n\u001b[32m    194\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:600\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    599\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    604\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    605\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    606\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\transformers\\modeling_utils.py:316\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    318\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\transformers\\modeling_utils.py:5061\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   5051\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5052\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   5054\u001b[39m     (\n\u001b[32m   5055\u001b[39m         model,\n\u001b[32m   5056\u001b[39m         missing_keys,\n\u001b[32m   5057\u001b[39m         unexpected_keys,\n\u001b[32m   5058\u001b[39m         mismatched_keys,\n\u001b[32m   5059\u001b[39m         offload_index,\n\u001b[32m   5060\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m5061\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5062\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5063\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5064\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5065\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5066\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5067\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5068\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5069\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5070\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5071\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5072\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5073\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5074\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5075\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5076\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5077\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5078\u001b[39m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[32m   5079\u001b[39m model.tie_weights()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\transformers\\modeling_utils.py:5327\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5324\u001b[39m     original_checkpoint_keys = \u001b[38;5;28mlist\u001b[39m(state_dict.keys())\n\u001b[32m   5325\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   5326\u001b[39m     original_checkpoint_keys = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m-> \u001b[39m\u001b[32m5327\u001b[39m         \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmeta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m)\u001b[49m.keys()\n\u001b[32m   5328\u001b[39m     )\n\u001b[32m   5330\u001b[39m \u001b[38;5;66;03m# Check if we are in a special state, i.e. loading from a state dict coming from a different architecture\u001b[39;00m\n\u001b[32m   5331\u001b[39m prefix = model.base_model_prefix\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\transformers\\modeling_utils.py:561\u001b[39m, in \u001b[36mload_state_dict\u001b[39m\u001b[34m(checkpoint_file, is_quantized, map_location, weights_only)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# Fallback to torch.load (if weights_only was explicitly False, do not check safety as this is known to be unsafe)\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m     \u001b[43mcheck_torch_load_is_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    563\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m map_location \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SBA\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-Us6BDj1P-py3.11\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1622\u001b[39m, in \u001b[36mcheck_torch_load_is_safe\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1620\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_torch_load_is_safe\u001b[39m():\n\u001b[32m   1621\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_greater_or_equal(\u001b[33m\"\u001b[39m\u001b[33m2.6\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1622\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1623\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mDue to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1624\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mto upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1625\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mwhen loading files with safetensors.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1626\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1627\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: Due to a serious vulnerability issue in `torch.load`, even with `weights_only=True`, we now require users to upgrade torch to at least v2.6 in order to use the function. This version restriction does not apply when loading files with safetensors.\nSee the vulnerability report here https://nvd.nist.gov/vuln/detail/CVE-2025-32434"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# Document\n",
    "embedded_documents = hf_embeddings.embed_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model: \\t\\t{model_name}\")\n",
    "print(f\"Dimension: \\t{len(embedded_documents[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "embedded_query = hf_embeddings.embed_query(\"LangChain 에 대해서 알려주세요.\")\n",
    "embedded_documents = hf_embeddings.embed_documents(texts)\n",
    "\n",
    "# 질문(embedded_query): LangChain 에 대해서 알려주세요.\n",
    "np.array(embedded_query) @ np.array(embedded_documents).T\n",
    "\n",
    "sorted_idx = (np.array(embedded_query) @ np.array(embedded_documents).T).argsort()[::-1]\n",
    "\n",
    "print(\"[Query] LangChain 에 대해서 알려주세요.\\n====================================\")\n",
    "for i, idx in enumerate(sorted_idx):\n",
    "    print(f\"[{i}] {texts[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `FlagEmbedding` 을 활용하는 방식\n",
    "\n",
    "**참고**\n",
    "- [FlagEmbedding - BGE-M3 Usage](https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/BGE_M3#usage)\n",
    "\n",
    "\n",
    "`FlagEmbedding` 에서 제공하는 세 가지 접근법을 조합하면, 더욱 강력한 검색 시스템을 구축할 수 있습니다.\n",
    "\n",
    "- Dense Vector: BGE-M3의 다국어, 다중 작업 능력을 기반으로 함\n",
    "- Lexical weight를 활용한 sparse embedding으로 정확한 단어 매칭을 수행\n",
    "- ColBERT의 multi-vector 접근법으로 문맥을 고려한 세밀한 매칭 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FlagEmbedding 설치\n",
    "!pip install -qU FlagEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "bge_embeddings = BGEM3FlagModel(\n",
    "    model_name, use_fp16=True\n",
    ")  # use_fp16을 True로 설정하면 약간의 성능 저하와 함께 계산 속도가 빨라집니다.\n",
    "\n",
    "bge_embedded = bge_embeddings.encode(\n",
    "    texts,\n",
    "    batch_size=12,\n",
    "    max_length=8192,  # 이렇게 긴 길이가 필요하지 않은 경우 더 작은 값을 설정하여 인코딩 프로세스의 속도를 높일 수 있습니다.\n",
    ")[\"dense_vecs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bge_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model: \\t\\t{model_name}\")\n",
    "print(f\"Dimension: \\t{len(embedded_documents[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "bge_flagmodel = BGEM3FlagModel(\n",
    "    \"BAAI/bge-m3\", use_fp16=True\n",
    ")  # use_fp16을 True로 설정하면 약간의 성능 저하와 함께 계산 속도가 빨라집니다.\n",
    "bge_encoded = bge_flagmodel.encode(texts, return_dense=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력(행, 열)\n",
    "bge_encoded[\"dense_vecs\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Embedding (Lexical Weight)\n",
    "\n",
    "Sparse embedding은 벡터의 대부분의 값이 0인 고차원 벡터를 사용하는 임베딩 방식입니다. Lexical weight를 활용한 방식은 단어의 중요도를 고려하여 임베딩을 생성합니다.\n",
    "\n",
    "**작동 방식**\n",
    "1. 각 단어에 대해 lexical weight(어휘적 가중치)를 계산합니다. 이는 TF-IDF나 BM25 같은 방법을 사용할 수 있습니다.\n",
    "2. 문서나 쿼리의 각 단어에 대해, 해당 단어의 lexical weight를 사용하여 sparse vector의 해당 차원에 값을 할당합니다.\n",
    "3. 결과적으로 문서나 쿼리는 대부분의 값이 0인 고차원 벡터로 표현됩니다.\n",
    "\n",
    "**장점**\n",
    "- 단어의 중요도를 직접적으로 반영할 수 있습니다.\n",
    "- 특정 단어나 구문을 정확히 매칭할 수 있습니다.\n",
    "- 계산이 상대적으로 빠릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bge_flagmodel = BGEM3FlagModel(\n",
    "    \"BAAI/bge-m3\", use_fp16=True\n",
    ")  # use_fp16을 True로 설정하면 약간의 성능 저하와 함께 계산 속도가 빨라집니다.\n",
    "bge_encoded = bge_flagmodel.encode(texts, return_sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_scores1 = bge_flagmodel.compute_lexical_matching_score(\n",
    "    bge_encoded[\"lexical_weights\"][0], bge_encoded[\"lexical_weights\"][0]\n",
    ")\n",
    "lexical_scores2 = bge_flagmodel.compute_lexical_matching_score(\n",
    "    bge_encoded[\"lexical_weights\"][0], bge_encoded[\"lexical_weights\"][1]\n",
    ")\n",
    "# 0 <-> 0\n",
    "print(lexical_scores1)\n",
    "# 0 <-> 1\n",
    "print(lexical_scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Vector (ColBERT)\n",
    "\n",
    "ColBERT(Contextualized Late Interaction over BERT)는 문서 검색을 위한 효율적인 방법입니다. 이 방식은 문서와 쿼리를 여러 개의 벡터로 표현하는 multi-vector 접근법을 사용합니다.\n",
    "\n",
    "**작동 방식**\n",
    "\n",
    "1. 문서의 각 토큰에 대해 별도의 벡터를 생성합니다. 즉, 하나의 문서는 여러 개의 벡터로 표현됩니다.\n",
    "2. 쿼리도 마찬가지로 각 토큰에 대해 별도의 벡터를 생성합니다.\n",
    "3. 검색 시, 쿼리의 각 토큰 벡터와 문서의 모든 토큰 벡터 사이의 유사도를 계산합니다.\n",
    "4. 이 유사도들을 종합하여 최종 검색 점수를 계산합니다.\n",
    "\n",
    "**장점**\n",
    "- 토큰 수준의 세밀한 매칭이 가능합니다.\n",
    "- 문맥을 고려한 임베딩을 생성할 수 있습니다.\n",
    "- 긴 문서에 대해서도 효과적으로 작동합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bge_flagmodel = BGEM3FlagModel(\n",
    "    \"BAAI/bge-m3\", use_fp16=True\n",
    ")  # use_fp16을 True로 설정하면 약간의 성능 저하와 함께 계산 속도가 빨라집니다.\n",
    "bge_encoded = bge_flagmodel.encode(texts, return_colbert_vecs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colbert_scores1 = bge_flagmodel.colbert_score(\n",
    "    bge_encoded[\"colbert_vecs\"][0], bge_encoded[\"colbert_vecs\"][0]\n",
    ")\n",
    "colbert_scores2 = bge_flagmodel.colbert_score(\n",
    "    bge_encoded[\"colbert_vecs\"][0], bge_encoded[\"colbert_vecs\"][1]\n",
    ")\n",
    "# 0 <-> 0\n",
    "print(colbert_scores1)\n",
    "# 0 <-> 1\n",
    "print(colbert_scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-Us6BDj1P-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
